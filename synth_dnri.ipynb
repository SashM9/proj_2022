{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdpmfpqIYMfpsbp1UVTPff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SashM9/proj_2022/blob/main/synth_dnri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def build_flags():\n",
        "    parser = argparse.ArgumentParser('')\n",
        "    parser.add_argument('--working_dir', required=True)\n",
        "    parser.add_argument('--gpu', action='store_true')\n",
        "    parser.add_argument('--seed', type=int, default=1)\n",
        "    parser.add_argument('--mode', choices=['train', 'eval', 'eval_fixedwindow'], required=True)\n",
        "    parser.add_argument('--load_model')\n",
        "    parser.add_argument('--load_best_model', action='store_true')\n",
        "    parser.add_argument('--continue_training', action='store_true')\n",
        "    parser.add_argument('--model_type', choices=['nri', 'dnri', 'fc_baseline'])\n",
        "\n",
        "    # Training Params\n",
        "    parser.add_argument('--num_epochs', type=int)\n",
        "    parser.add_argument('--lr', type=float, default=1e-3)\n",
        "    parser.add_argument('--mom', type=float, default=0)\n",
        "    parser.add_argument('--batch_size', type=int, default=32)\n",
        "    parser.add_argument('--sub_batch_size', type=int)\n",
        "    parser.add_argument('--val_batch_size', type=int)\n",
        "    parser.add_argument('--val_interval', type=int, default=5)\n",
        "    parser.add_argument('--test', action='store_true')\n",
        "    parser.add_argument('--use_adam', action='store_true')\n",
        "    parser.add_argument('--lr_decay_factor', type=float)\n",
        "    parser.add_argument('--lr_decay_steps', type=int)\n",
        "    parser.add_argument('--clip_grad_norm', type=float)\n",
        "    parser.add_argument('--verbose', action='store_true')\n",
        "    parser.add_argument('--tune_on_nll', action='store_true')\n",
        "    parser.add_argument('--val_teacher_forcing', action='store_true')\n",
        "    parser.add_argument('--accumulate_steps', type=int, default=1)\n",
        "    parser.add_argument('--max_burn_in_count', type=int, default=-1)\n",
        "    \n",
        "    # Model Params\n",
        "    parser.add_argument('--no_prior', action='store_true')\n",
        "    parser.add_argument('--avg_prior', action='store_true')\n",
        "    parser.add_argument('--add_uniform_prior', action='store_true')\n",
        "    parser.add_argument('--prior_num_layers', type=int, default=1)\n",
        "    parser.add_argument('--prior_hidden_size', type=int, default=256)\n",
        "    parser.add_argument('--use_learned_prior', action='store_true')\n",
        "    parser.add_argument('--graph_type', choices=['static', 'dynamic'])\n",
        "    parser.add_argument('--avg_encoder_inputs', action='store_true')\n",
        "    parser.add_argument('--use_dynamic_graph', action='store_true')\n",
        "    parser.add_argument('--use_static_encoder', action='store_true')\n",
        "    parser.add_argument('--decoder_type')\n",
        "    parser.add_argument('--encoder_rnn_type', choices=['lstm', 'gru'], default='lstm')\n",
        "    parser.add_argument('--decoder_rnn_type', choices=['lstm', 'gru'], default='gru')\n",
        "    parser.add_argument('--encoder_hidden', type=int, default=256)\n",
        "    parser.add_argument('--encoder_rnn_hidden', type=int)\n",
        "    parser.add_argument('--num_edge_types', type=int, default=2)\n",
        "    parser.add_argument('--encoder_dropout', type=float, default=0.0)\n",
        "    parser.add_argument('--encoder_unidirectional', action='store_true')\n",
        "    parser.add_argument('--encoder_bidirectional', action='store_true')\n",
        "    parser.add_argument('--encoder_no_factor', action='store_true', default=False)\n",
        "    parser.add_argument('--decoder_hidden', type=int, default=256)\n",
        "    parser.add_argument('--decoder_msg_hidden', type=int, default=256)\n",
        "    parser.add_argument('--decoder_dropout', type=float, default=0.0)\n",
        "    parser.add_argument('--skip_first', action='store_true', default=False)\n",
        "    parser.add_argument('--uniform_prior', action='store_true')\n",
        "    parser.add_argument('--no_edge_prior', type=float)\n",
        "    parser.add_argument('--teacher_forcing_steps', type=int, default=10)\n",
        "    parser.add_argument('--gumbel_temp', type=float, default=0.5)\n",
        "    parser.add_argument('--train_hard_sample', action='store_true')\n",
        "    parser.add_argument('--normalize_kl', action='store_true')\n",
        "    parser.add_argument('--normalize_kl_per_var', action='store_true')\n",
        "    parser.add_argument('--normalize_nll', action='store_true')\n",
        "    parser.add_argument('--normalize_nll_per_var', action='store_true')\n",
        "    parser.add_argument('--kl_coef', type=float, default=1.)\n",
        "    parser.add_argument('--no_encoder_bn', action='store_true')\n",
        "    parser.add_argument('--encoder_mlp_hidden', type=int, default=256)\n",
        "    parser.add_argument('--encoder_mlp_num_layers', type=int, default=1)\n",
        "    parser.add_argument('--rnn_hidden', type=int, default=64)\n",
        "    parser.add_argument('--teacher_forcing_prior', action='store_true')\n",
        "    parser.add_argument('--decoder_rnn_hidden', type=int)\n",
        "    parser.add_argument('--encoder_save_eval_memory', action='store_true')\n",
        "    parser.add_argument('--encoder_normalize_mode', choices=[None, 'normalize_inp', 'normalize_all'])\n",
        "    parser.add_argument('--normalize_inputs', action='store_true')\n",
        "    #Modes\n",
        "    return parser"
      ],
      "metadata": {
        "id": "P1wRIngkUPxQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "\n",
        "class RefNRIMLP(nn.Module):\n",
        "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
        "\n",
        "    def __init__(self, n_in, n_hid, n_out, do_prob=0., no_bn=False):\n",
        "        super(RefNRIMLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_in, n_hid),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_out),\n",
        "            nn.ELU(inplace=True)\n",
        "        )\n",
        "        if no_bn:\n",
        "            self.bn = None\n",
        "        else:\n",
        "            self.bn = nn.BatchNorm1d(n_out)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def batch_norm(self, inputs):\n",
        "        orig_shape = inputs.shape\n",
        "        x = inputs.view(-1, inputs.size(-1))\n",
        "        x = self.bn(x)\n",
        "        return x.view(orig_shape)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Input shape: [num_sims, num_things, num_features]\n",
        "        x = self.model(inputs)\n",
        "        if self.bn is not None:\n",
        "            return self.batch_norm(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    return - torch.log(eps - torch.log(U + eps))\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    if logits.is_cuda:\n",
        "        gumbel_noise = gumbel_noise.cuda()\n",
        "    y = logits + gumbel_noise\n",
        "    return F.softmax(y / tau, dim=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape)\n",
        "        if y_soft.is_cuda:\n",
        "            y_hard = y_hard.cuda()\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = y_hard - y_soft.data + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n",
        "\n",
        "\n",
        "def get_graph_info(masks, num_vars, use_edge2node=True):\n",
        "    if num_vars == 1:\n",
        "        return None, None, None\n",
        "    edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "    tmp = torch.where(edges)\n",
        "    send_edges = tmp[0]\n",
        "    recv_edges = tmp[1]\n",
        "    tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1)\n",
        "    if use_edge2node:\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        return send_edges, recv_edges, edge2node_inds\n",
        "    else:\n",
        "        return send_edges, recv_edges"
      ],
      "metadata": {
        "id": "nujWHRp4W0CD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class BaseEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_vars, graph_type):\n",
        "        super(BaseEncoder, self).__init__()\n",
        "        self.num_vars = num_vars\n",
        "        self.graph_type = graph_type\n",
        "        self.dynamic = graph_type == 'dynamic'\n",
        "\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges).transpose()), requires_grad=False)\n",
        "    \n",
        "    def node2edge(self, node_embeddings):\n",
        "        if self.dynamic:\n",
        "            '''\n",
        "            node_embeddings: [batch, num_nodes, embed_size]\n",
        "            '''\n",
        "            send_embed = node_embeddings[:, self.send_edges, :, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :, :]\n",
        "            return torch.cat([send_embed, recv_embed], dim=3)\n",
        "        else:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "            return torch.cat([send_embed, recv_embed], dim=2)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        #TODO: there may be a more efficient way of doing this, but shrug\n",
        "        if self.dynamic:\n",
        "            old_shape = edge_embeddings.shape\n",
        "            tmp_embeddings = edge_embeddings.view(old_shape[0], old_shape[1], -1)\n",
        "            incoming = torch.matmul(self.edge2node_mat, tmp_embeddings).view(old_shape[0], -1, old_shape[2], old_shape[3])\n",
        "        else:\n",
        "            incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        return incoming/(self.num_vars-1) #TODO: do we want this average?\n",
        "\n",
        "    def forward(self, inputs, state=None, return_state=False):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class RefMLPEncoder(BaseEncoder):\n",
        "    def __init__(self, params):\n",
        "        num_vars = params['num_vars']\n",
        "        inp_size = inp_size = params['input_size']*params['input_time_steps']\n",
        "        hidden_size = params['encoder_hidden']\n",
        "        num_edges = params['num_edge_types']\n",
        "        factor = not params['encoder_no_factor']\n",
        "        no_bn = False\n",
        "        graph_type = params['graph_type']\n",
        "        super(RefMLPEncoder, self).__init__(num_vars, graph_type)\n",
        "        dropout = params['encoder_dropout']\n",
        "        self.input_time_steps = params['input_time_steps']\n",
        "        self.dynamic = self.graph_type == 'dynamic'\n",
        "        self.factor = factor\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        if self.factor:\n",
        "            self.mlp4 = RefNRIMLP(hidden_size * 3, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "            print(\"Using factor graph MLP encoder.\")\n",
        "        else:\n",
        "            self.mlp4 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "            print(\"Using MLP encoder.\")\n",
        "        num_layers = params['encoder_mlp_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.fc_out = nn.Linear(hidden_size, num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['encoder_mlp_hidden']\n",
        "            layers = [nn.Linear(hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, num_edges))\n",
        "            self.fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def node2edge(self, node_embeddings):\n",
        "        send_embed = node_embeddings[:, self.send_edges, :]\n",
        "        recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "        return torch.cat([send_embed, recv_embed], dim=2)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        return incoming/(self.num_vars-1) #TODO: do we want this average?\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def merge_states(self, states):\n",
        "        return torch.cat(states, dim=0)\n",
        "\n",
        "    def forward(self, inputs, state=None, return_state=False):\n",
        "        if inputs.size(1) > self.input_time_steps:\n",
        "            inputs = inputs[:, -self.input_time_steps:]\n",
        "        elif inputs.size(1) < self.input_time_steps:\n",
        "            begin_inp = inputs[:, 0:1].expand(-1, self.input_time_steps-inputs.size(1), -1, -1)\n",
        "            inputs = torch.cat([begin_inp, inputs], dim=1)\n",
        "        if state is not None:\n",
        "            inputs = torch.cat([state, inputs], 1)[:, -self.input_time_steps:]\n",
        "        x = inputs.transpose(1, 2).contiguous().view(inputs.size(0), inputs.size(2), -1)\n",
        "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
        "        x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp2(x)\n",
        "        x_skip = x\n",
        "\n",
        "        if self.factor:\n",
        "            x = self.edge2node(x)\n",
        "            x = self.mlp3(x)\n",
        "            x = self.node2edge(x)\n",
        "            x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "            x = self.mlp4(x)\n",
        "        else:\n",
        "            x = self.mlp3(x)\n",
        "            x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "            x = self.mlp4(x)\n",
        "        result =  self.fc_out(x)\n",
        "        result_dict = {\n",
        "            'logits': result,\n",
        "            'state': inputs,\n",
        "        }\n",
        "        return result_dict"
      ],
      "metadata": {
        "id": "XB4TQCpzWsqW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GraphRNNDecoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(GraphRNNDecoder, self).__init__()\n",
        "        self.embedder = None\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "        input_size = params['input_size']\n",
        "        self.gpu = params['gpu']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2*n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = torch.FloatTensor(encode_onehot(self.recv_edges))\n",
        "        if self.gpu:\n",
        "            self.edge2node_mat = self.edge2node_mat.cuda(non_blocking=True)\n",
        "\n",
        "    def single_step_forward(self, inputs, rel_type, hidden):\n",
        "        # Inputs: [batch, num_atoms, num_dims]\n",
        "        # Hidden: [batch, num_atoms, msg_out]\n",
        "        # rel_type: [batch_size, num_atoms*(num_atoms-1), num_edge_types]\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        if inputs.is_cuda:\n",
        "            all_msgs = torch.cuda.FloatTensor(pre_msg.size(0), pre_msg.size(1),\n",
        "                                              self.msg_out_shape).fill_(0.)\n",
        "        else:\n",
        "            all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                            self.msg_out_shape)\n",
        "        \n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "            norm = float(len(self.msg_fc2)) - 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "            norm = float(len(self.msg_fc2))\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: to exclude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=self.dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "            msg = msg * rel_type[:, :, i:i+1]\n",
        "            all_msgs += msg/norm\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=self.dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden\n",
        "\n",
        "    def forward(self, inputs, sampled_edges, teacher_forcing=False, teacher_forcing_steps=-1, return_state=False,\n",
        "                prediction_steps=-1, state=None, burn_in_masks=None):\n",
        "\n",
        "        time_steps = inputs.size(1)\n",
        "\n",
        "        # inputs has shape\n",
        "        # [batch_size, num_timesteps, num_atoms, num_feats]\n",
        "\n",
        "        if prediction_steps > 0:\n",
        "            pred_steps = prediction_steps\n",
        "        else:\n",
        "            pred_steps = time_steps\n",
        "\n",
        "        if len(sampled_edges.shape) == 3:\n",
        "            sampled_edges = sampled_edges.unsqueeze(1).expand(sampled_edges.size(0), pred_steps, sampled_edges.size(1), sampled_edges.size(2))\n",
        "        # sampled_edges has shape:\n",
        "        # [batch_size, num_time_steps, num_atoms*(num_atoms-1), num_edge_types]\n",
        "        # represents the sampled edges in the graph\n",
        "\n",
        "        # Hidden size: [batch, num_atoms, msg_out]\n",
        "        if state is None:\n",
        "            if inputs.is_cuda:\n",
        "                hidden = torch.cuda.FloatTensor(inputs.size(0), inputs.size(2), self.msg_out_shape).fill_(0.)\n",
        "            else:\n",
        "                hidden = torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape)\n",
        "        else:\n",
        "            hidden = state\n",
        "        if teacher_forcing_steps == -1:\n",
        "            teacher_forcing_steps = inputs.size(1)\n",
        "        \n",
        "        pred_all = []\n",
        "        for step in range(0, pred_steps):\n",
        "            if burn_in_masks is not None and step != 0:\n",
        "                current_masks = burn_in_masks[:, step, :]\n",
        "                ins = inputs[:, step, :]*current_masks + pred_all[-1]*(1 - current_masks)\n",
        "            elif step == 0 or (teacher_forcing and step < teacher_forcing_steps): \n",
        "                ins = inputs[:, step, :]\n",
        "            else:\n",
        "                ins = pred_all[-1]\n",
        "            edges = sampled_edges[:, step, :]\n",
        "            pred, hidden = self.single_step_forward(ins, edges, hidden)\n",
        "\n",
        "            pred_all.append(pred)\n",
        "        preds = torch.stack(pred_all, dim=1)\n",
        "\n",
        "        if return_state:\n",
        "            return preds, hidden\n",
        "        else:\n",
        "            return preds"
      ],
      "metadata": {
        "id": "1D4-d7QfXCt1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class BaseNRI(nn.Module):\n",
        "    def __init__(self, num_vars, encoder, decoder, params):\n",
        "        super(BaseNRI, self).__init__()\n",
        "        # Model Params\n",
        "        self.num_vars = num_vars\n",
        "        self.decoder = decoder\n",
        "        self.encoder = encoder\n",
        "        self.num_edge_types = params.get('num_edge_types')\n",
        "\n",
        "        # Training params\n",
        "        self.gumbel_temp = params.get('gumbel_temp')\n",
        "        self.train_hard_sample = params.get('train_hard_sample')\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        if params.get('no_edge_prior') is not None:\n",
        "            prior = np.zeros(self.num_edge_types)\n",
        "            prior.fill((1 - params['no_edge_prior'])/(self.num_edge_types - 1))\n",
        "            prior[0] = params['no_edge_prior']\n",
        "            log_prior = torch.FloatTensor(np.log(prior))\n",
        "            log_prior = torch.unsqueeze(log_prior, 0)\n",
        "            log_prior = torch.unsqueeze(log_prior, 0)\n",
        "            if params['gpu']:\n",
        "                log_prior = log_prior.cuda(non_blocking=True)\n",
        "            self.log_prior = log_prior\n",
        "            print(\"USING NO EDGE PRIOR: \",self.log_prior)\n",
        "        else:\n",
        "            print(\"USING UNIFORM PRIOR\")\n",
        "            prior = np.zeros(self.num_edge_types)\n",
        "            prior.fill(1.0/self.num_edge_types)\n",
        "            log_prior = torch.FloatTensor(np.log(prior))\n",
        "            log_prior = torch.unsqueeze(log_prior, 0)\n",
        "            log_prior = torch.unsqueeze(log_prior, 0)\n",
        "            if params['gpu']:\n",
        "                log_prior = log_prior.cuda(non_blocking=True)\n",
        "            self.log_prior = log_prior\n",
        "\n",
        "        self.normalize_kl = params.get('normalize_kl', False)\n",
        "        self.normalize_kl_per_var = params.get('normalize_kl_per_var', False)\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.kl_coef = params.get('kl_coef', 1.)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.timesteps = params.get('timesteps', 0)\n",
        "        self.extra_context = params.get('embedder_time_bins', 0)\n",
        "        self.burn_in_steps = params.get('train_burn_in_steps')\n",
        "        self.no_prior = params.get('no_prior', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "\n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_edges=False, return_logits=False):\n",
        "        # Should be shape [batch, num_edges, edge_dim]\n",
        "        encoder_results = self.encoder(inputs)\n",
        "        logits = encoder_results['logits']\n",
        "        old_shape = logits.shape\n",
        "        hard_sample = (not is_train) or self.train_hard_sample\n",
        "        edges = model_utils.gumbel_softmax(\n",
        "            logits.view(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=hard_sample).view(old_shape)\n",
        "        if not is_train and teacher_forcing:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        output = self.decoder(inputs[:, self.extra_context:-1], edges, \n",
        "                              teacher_forcing=teacher_forcing, \n",
        "                              teacher_forcing_steps=teacher_forcing_steps)\n",
        "        if len(inputs.shape) == 4:\n",
        "            target = inputs[:, self.extra_context+1:, :, :]\n",
        "        else:\n",
        "            target = inputs[:, self.extra_context+1:, :]\n",
        "        loss_nll = self.nll(output, target)\n",
        "        prob = F.softmax(logits, dim=-1)\n",
        "        if self.no_prior:\n",
        "            loss_kl = torch.cuda.FloatTensor([0.0])\n",
        "        elif self.log_prior is not None:\n",
        "            loss_kl = self.kl_categorical(prob)\n",
        "        else:\n",
        "            loss_kl = self.kl_categorical_uniform(prob)\n",
        "        loss = loss_nll + self.kl_coef*loss_kl\n",
        "        loss = loss.mean()\n",
        "        if return_edges:\n",
        "            return loss, loss_nll, loss_kl, edges\n",
        "        elif return_logits:\n",
        "            return loss, loss_nll, loss_kl, logits, output\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "        \n",
        "    def predict_future(self, data_encoder, data_decoder):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical(self, preds, eps=1e-16):\n",
        "        kl_div = preds*(torch.log(preds+eps) - self.log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "    \n",
        "    def kl_categorical_uniform(self, preds, eps=1e-16):\n",
        "        kl_div = preds*(torch.log(preds + eps) + np.log(self.num_edge_types))\n",
        "        if self.normalize_kl:\n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean()\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)/self.num_edge_types\n",
        "    \n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "class StaticNRI(BaseNRI):\n",
        "\n",
        "    def copy_state(self, decoder_state):\n",
        "        if isinstance(decoder_state, tuple) or isinstance(decoder_state, list):\n",
        "            current_decoder_state = (decoder_state[0].clone(), decoder_state[1].clone())\n",
        "        else:\n",
        "            current_decoder_state = decoder_state.clone()\n",
        "        return current_decoder_state\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        encoder_dict = self.encoder(inputs)\n",
        "        logits = encoder_dict['logits']\n",
        "        old_shape = logits.shape\n",
        "        edges = nn.functional.gumbel_softmax(\n",
        "            logits.view(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=True).view(old_shape)\n",
        "        tmp_predictions, decoder_state = self.decoder(inputs[:, :-1], edges, teacher_forcing=True, teacher_forcing_steps=-1, return_state=True)\n",
        "        decoder_inputs = inputs[:, -1].unsqueeze(1)\n",
        "        predictions = self.decoder(decoder_inputs, edges, prediction_steps=prediction_steps, teacher_forcing=False, state=decoder_state)\n",
        "        if return_everything:\n",
        "            predictions = torch.cat([tmp_predictions, predictions], dim=1)\n",
        "        if return_edges:\n",
        "            return predictions, edges\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "    def merge_states(self, states):\n",
        "        if isinstance(states[0], tuple) or isinstance(states[0], list):\n",
        "            result0 = torch.cat([x[0] for x in states], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in states], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(states, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size, return_edges=False):\n",
        "        burn_in_inputs = inputs[:, :burn_in_steps]\n",
        "        encoder_dict = self.encoder(burn_in_inputs)\n",
        "        logits = encoder_dict['logits']\n",
        "        old_shape = logits.shape\n",
        "        edges = nn.functional.gumbel_softmax(\n",
        "            logits.view(-1, self.num_edge_types),\n",
        "            tau=self.gumbel_temp,\n",
        "            hard=True).view(old_shape)\n",
        "        _, decoder_state = self.decoder(burn_in_inputs[:, :-1], edges, teacher_forcing=True, teacher_forcing_steps=-1, return_state=True)\n",
        "        all_timestep_preds = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            encoder_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                tmp_ind = window_ind + step\n",
        "                predictions = inputs[:, tmp_ind:tmp_ind+1]\n",
        "                predictions, decoder_state = self.decoder(predictions,edges, teacher_forcing=False, prediction_steps=1, return_state=True, state=decoder_state)\n",
        "                current_batch_preds.append(predictions)\n",
        "                decoder_states.append(self.copy_state(decoder_state))\n",
        "            batch_decoder_state = self.merge_states(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            batch_edges = edges.expand(current_batch_preds.size(0), -1, -1)\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_preds, batch_decoder_state =self.decoder(current_batch_preds, batch_edges, teacher_forcing=False, prediction_steps=1, return_state=True, state=batch_decoder_state) \n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.cat(current_timestep_preds, dim=1))\n",
        "        result = torch.cat(all_timestep_preds, dim=0)\n",
        "        if return_edges:\n",
        "            return result.unsqueeze(0), edges\n",
        "        else:\n",
        "            return result.unsqueeze(0)\n",
        "\n",
        "    \n",
        "class DynamicNRI(BaseNRI):\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        encoder_dict = self.encoder(inputs)\n",
        "        burn_in_logits = encoder_dict['logits']\n",
        "        encoder_state = encoder_dict['state']\n",
        "        old_shape = burn_in_logits.shape\n",
        "        burn_in_edges = nn.functional.gumbel_softmax(\n",
        "            burn_in_logits.view(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=True).view(old_shape)\n",
        "        burn_in_predictions, decoder_state = self.decoder(inputs, burn_in_edges, teacher_forcing=True, teacher_forcing_steps=-1, return_state=True)\n",
        "        prev_preds = burn_in_predictions[:, -1].unsqueeze(1)\n",
        "        preds = [prev_preds]\n",
        "        all_edges = [burn_in_edges]\n",
        "        for step in range(prediction_steps-1):\n",
        "            encoder_dict = self.encoder(prev_preds, encoder_state)\n",
        "            logits = encoder_dict['logits']\n",
        "            encoder_state = encoder_dict['state']\n",
        "            old_shape = logits.shape\n",
        "            edges = nn.functional.gumbel_softmax(\n",
        "                logits.view(-1, self.num_edge_types),\n",
        "                tau=self.gumbel_temp,\n",
        "                hard=True).view(old_shape)\n",
        "            if return_edges:\n",
        "                all_edges.append(edges)\n",
        "            prev_preds, decoder_state = self.decoder(prev_preds, edges, teacher_forcing=False, prediction_steps=1, return_state=True, state=decoder_state)\n",
        "            preds.append(prev_preds)\n",
        "        preds = torch.cat(preds, dim=1)\n",
        "        if return_everything:\n",
        "            preds = torch.cat([burn_in_predictions[:, :-1], preds], dim=1)\n",
        "        if return_edges:\n",
        "            return preds, torch.stack(all_edges, dim=1)\n",
        "        else:\n",
        "            return preds\n",
        "\n",
        "    def copy_states(self, encoder_state, decoder_state):\n",
        "        if isinstance(encoder_state, tuple) or isinstance(encoder_state, list):\n",
        "            current_encoder_state = (encoder_state[0].clone(), encoder_state[1].clone())\n",
        "        else:\n",
        "            current_encoder_state = encoder_state.clone()\n",
        "        if isinstance(decoder_state, tuple) or isinstance(decoder_state, list):\n",
        "            current_decoder_state = (decoder_state[0].clone(), decoder_state[1].clone())\n",
        "        else:\n",
        "            current_decoder_state = decoder_state.clone()\n",
        "        return current_encoder_state, current_decoder_state\n",
        "\n",
        "    def merge_states(self, states):\n",
        "        if isinstance(states[0], tuple) or isinstance(states[0], list):\n",
        "            result0 = torch.cat([x[0] for x in states], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in states], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(states, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size, return_edges=False):\n",
        "        burn_in_inputs = inputs[:, :burn_in_steps-1]\n",
        "        encoder_dict = self.encoder(burn_in_inputs)\n",
        "        burn_in_logits = encoder_dict['logits']\n",
        "        encoder_state = encoder_dict['state']\n",
        "        old_shape = burn_in_logits.shape\n",
        "        burn_in_edges = nn.functional.gumbel_softmax(\n",
        "            burn_in_logits.view(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=True).view(old_shape)\n",
        "        burn_in_predictions, decoder_state = self.decoder(burn_in_inputs, burn_in_edges, teacher_forcing=True, teacher_forcing_steps=-1, return_state=True)\n",
        "        all_timestep_preds = []\n",
        "        all_timestep_edges = []\n",
        "        all_edges = [] \n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1) - 1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            current_batch_edges = []\n",
        "            encoder_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                tmp_ind = window_ind + step\n",
        "                predictions = inputs[:, tmp_ind:tmp_ind+1]\n",
        "                encoder_dict = self.encoder(predictions, encoder_state)\n",
        "                logits = encoder_dict['logits']\n",
        "                encoder_state = encoder_dict['state']\n",
        "                old_shape = logits.shape\n",
        "                edges = nn.functional.gumbel_softmax(\n",
        "                    logits.view(-1, self.num_edge_types),\n",
        "                    tau=self.gumbel_temp,\n",
        "                    hard=True).view(old_shape)\n",
        "                predictions, decoder_state = self.decoder(predictions, edges, teacher_forcing=False, prediction_steps=1, return_state=True, state=decoder_state)\n",
        "                current_batch_preds.append(predictions)\n",
        "                if return_edges:\n",
        "                    current_batch_edges.append(edges)\n",
        "                tmp_encoder, tmp_decoder = self.copy_states(encoder_state, decoder_state)\n",
        "                encoder_states.append(tmp_encoder)\n",
        "                decoder_states.append(tmp_decoder)\n",
        "            batch_encoder_state = self.encoder.merge_states(encoder_states)\n",
        "            batch_decoder_state = self.merge_states(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            if return_edges:\n",
        "                current_timestep_edges = [torch.cat(current_batch_edges, 0)]\n",
        "                \n",
        "            for step in range(prediction_steps - 1):\n",
        "                encoder_dict = self.encoder(current_batch_preds, batch_encoder_state)\n",
        "                logits = encoder_dict['logits']\n",
        "                batch_encoder_state = encoder_dict['state']\n",
        "                old_shape = logits.shape\n",
        "                edges = nn.functional.gumbel_softmax(\n",
        "                    logits.view(-1, self.num_edge_types),\n",
        "                    tau=self.gumbel_temp,\n",
        "                    hard=True).view(old_shape)\n",
        "                if return_edges:\n",
        "                    current_timestep_edges.append(edges)\n",
        "                current_batch_preds, batch_decoder_state = self.decoder(current_batch_preds, edges, teacher_forcing=False, prediction_steps=1, return_state=True, state=batch_decoder_state)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.cat(current_timestep_preds, dim=1))\n",
        "            if return_edges:\n",
        "                all_timestep_edges.append(torch.cat(current_timestep_edges, dim=1))\n",
        "        result = torch.cat(all_timestep_preds, dim=0)\n",
        "        if return_edges:\n",
        "            edges = torch.cat(all_timestep_edges, dim=0)\n",
        "            return result.unsqueeze(0), edges.unsqueeze(0)\n",
        "        else:\n",
        "            return result.unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "5PmaTKrfXdTQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "class DNRI(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI, self).__init__()\n",
        "        # Model Params\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.encoder = DNRI_Encoder(params)\n",
        "        decoder_type = params.get('decoder_type', None)\n",
        "        if decoder_type == 'ref_mlp':\n",
        "            self.decoder = DNRI_MLP_Decoder(params)\n",
        "        else:\n",
        "            self.decoder = DNRI_Decoder(params)\n",
        "        self.num_edge_types = params.get('num_edge_types')\n",
        "\n",
        "        # Training params\n",
        "        self.gumbel_temp = params.get('gumbel_temp')\n",
        "        self.train_hard_sample = params.get('train_hard_sample')\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        \n",
        "        self.normalize_kl = params.get('normalize_kl', False)\n",
        "        self.normalize_kl_per_var = params.get('normalize_kl_per_var', False)\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.kl_coef = params.get('kl_coef', 1.)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.timesteps = params.get('timesteps', 0)\n",
        "        self.burn_in_steps = params.get('train_burn_in_steps')\n",
        "        self.teacher_forcing_prior = params.get('teacher_forcing_prior', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.add_uniform_prior = params.get('add_uniform_prior')\n",
        "        if self.add_uniform_prior:\n",
        "            if params.get('no_edge_prior') is not None:\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill((1 - params['no_edge_prior'])/(self.num_edge_types - 1))\n",
        "                prior[0] = params['no_edge_prior']\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "                print(\"USING NO EDGE PRIOR: \",self.log_prior)\n",
        "            else:\n",
        "                print(\"USING UNIFORM PRIOR\")\n",
        "                prior = np.zeros(self.num_edge_types)\n",
        "                prior.fill(1.0/self.num_edge_types)\n",
        "                log_prior = torch.FloatTensor(np.log(prior))\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                log_prior = torch.unsqueeze(log_prior, 0)\n",
        "                if params['gpu']:\n",
        "                    log_prior = log_prior.cuda(non_blocking=True)\n",
        "                self.log_prior = log_prior\n",
        "\n",
        "    def single_step_forward(self, inputs, decoder_hidden, edge_logits, hard_sample):\n",
        "        old_shape = edge_logits.shape\n",
        "        edges = model_utils.gumbel_softmax(\n",
        "            edge_logits.reshape(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=hard_sample).view(old_shape)\n",
        "        predictions, decoder_hidden = self.decoder(inputs, decoder_hidden, edges)\n",
        "        return predictions, decoder_hidden, edges\n",
        "\n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_edges=False, return_logits=False, use_prior_logits=False):\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_edges = []\n",
        "        all_predictions = []\n",
        "        all_priors = []\n",
        "        hard_sample = (not is_train) or self.train_hard_sample\n",
        "        prior_logits, posterior_logits, _ = self.encoder(inputs[:, :-1])\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            if not use_prior_logits:\n",
        "                current_p_logits = posterior_logits[:, step]\n",
        "            else:\n",
        "                current_p_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_p_logits, hard_sample)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        prob = F.softmax(posterior_logits, dim=-1)\n",
        "        loss_kl = self.kl_categorical_learned(prob, prior_logits)\n",
        "        if self.add_uniform_prior:\n",
        "            loss_kl = 0.5*loss_kl + 0.5*self.kl_categorical_avg(prob)\n",
        "        loss = loss_nll + self.kl_coef*loss_kl\n",
        "        loss = loss.mean()\n",
        "\n",
        "        if return_edges:\n",
        "            return loss, loss_nll, loss_kl, edges\n",
        "        elif return_logits:\n",
        "            return loss, loss_nll, loss_kl, posterior_logits, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_edges=False, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(1)\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        all_edges = []\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "            if return_everything:\n",
        "                all_edges.append(edges)\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        if return_edges:\n",
        "            edges = torch.stack(all_edges, dim=1)\n",
        "            return predictions, edges\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size, return_edges=False):\n",
        "        print(\"INPUT SHAPE: \",inputs.shape)\n",
        "        prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, _ = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "        all_timestep_preds = []\n",
        "        all_timestep_edges = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            current_batch_edges = []\n",
        "            prior_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step] \n",
        "                current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "                predictions, decoder_hidden, _ = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_prior = self.encoder.copy_states(prior_hidden)\n",
        "                tmp_decoder = self.copy_states(decoder_hidden)\n",
        "                prior_states.append(tmp_prior)\n",
        "                decoder_states.append(tmp_decoder)\n",
        "                if return_edges:\n",
        "                    current_batch_edges.append(current_edge_logits.cpu())\n",
        "            batch_prior_hidden = self.encoder.merge_hidden(prior_states)\n",
        "            batch_decoder_hidden = self.merge_hidden(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            if return_edges:\n",
        "                current_batch_edges = torch.cat(current_batch_edges, 0)\n",
        "                current_timestep_edges = [current_batch_edges]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_edge_logits, batch_prior_hidden = self.encoder.single_step_forward(current_batch_preds, batch_prior_hidden)\n",
        "                current_batch_preds, batch_decoder_hidden, _ = self.single_step_forward(current_batch_preds, batch_decoder_hidden, current_batch_edge_logits, True)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "                if return_edges:\n",
        "                    current_timestep_edges.append(current_batch_edge_logits.cpu())\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "            if return_edges:\n",
        "                all_timestep_edges.append(torch.stack(current_timestep_edges, dim=1))\n",
        "        result =  torch.cat(all_timestep_preds, dim=0)\n",
        "        if return_edges:\n",
        "            edge_result = torch.cat(all_timestep_edges, dim=0)\n",
        "            return result.unsqueeze(0), edge_result.unsqueeze(0)\n",
        "        else:\n",
        "            return result.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_learned(self, preds, prior_logits):\n",
        "        log_prior = nn.LogSoftmax(dim=-1)(prior_logits)\n",
        "        kl_div = preds*(torch.log(preds + 1e-16) - log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def kl_categorical_avg(self, preds, eps=1e-16):\n",
        "        avg_preds = preds.mean(dim=2)\n",
        "        kl_div = avg_preds*(torch.log(avg_preds+eps) - self.log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            return kl_div.sum() / (self.num_vars * preds.size(0))\n",
        "        else:\n",
        "            return kl_div.view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "class DNRI_Encoder(nn.Module):\n",
        "    # Here, encoder also produces prior\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Encoder, self).__init__()\n",
        "        num_vars = params['num_vars']\n",
        "        self.num_edges = params['num_edge_types']\n",
        "        self.sepaate_prior_encoder = params.get('separate_prior_encoder', False)\n",
        "        no_bn = False\n",
        "        dropout = params['encoder_dropout']\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges).transpose()), requires_grad=False)\n",
        "        self.save_eval_memory = params.get('encoder_save_eval_memory', False)\n",
        "\n",
        "\n",
        "        hidden_size = params['encoder_hidden']\n",
        "        rnn_hidden_size = params['encoder_rnn_hidden']\n",
        "        rnn_type = params['encoder_rnn_type']\n",
        "        inp_size = params['input_size']\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp4 = RefNRIMLP(hidden_size * 3, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "\n",
        "        if rnn_hidden_size is None:\n",
        "            rnn_hidden_size = hidden_size\n",
        "        if rnn_type == 'lstm':\n",
        "            self.forward_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'gru':\n",
        "            self.forward_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        out_hidden_size = 2*rnn_hidden_size\n",
        "        num_layers = params['encoder_mlp_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.encoder_fc_out = nn.Linear(out_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['encoder_mlp_hidden']\n",
        "            layers = [nn.Linear(out_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.encoder_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        num_layers = params['prior_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.prior_fc_out = nn.Linear(rnn_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['prior_hidden_size']\n",
        "            layers = [nn.Linear(rnn_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.prior_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def node2edge(self, node_embeddings):\n",
        "        # Input size: [batch, num_vars, num_timesteps, embed_size]\n",
        "        if len(node_embeddings.shape) == 4:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :, :]\n",
        "        else:\n",
        "            send_embed = node_embeddings[:, self.send_edges, :]\n",
        "            recv_embed = node_embeddings[:, self.recv_edges, :]\n",
        "        return torch.cat([send_embed, recv_embed], dim=-1)\n",
        "\n",
        "    def edge2node(self, edge_embeddings):\n",
        "        if len(edge_embeddings.shape) == 4:\n",
        "            old_shape = edge_embeddings.shape\n",
        "            tmp_embeddings = edge_embeddings.view(old_shape[0], old_shape[1], -1)\n",
        "            incoming = torch.matmul(self.edge2node_mat, tmp_embeddings).view(old_shape[0], -1, old_shape[2], old_shape[3])\n",
        "        else:\n",
        "            incoming = torch.matmul(self.edge2node_mat, edge_embeddings)\n",
        "        return incoming/(self.num_vars-1) #TODO: do we want this average?\n",
        "\n",
        "\n",
        "    def copy_states(self, prior_state):\n",
        "        if isinstance(prior_state, tuple) or isinstance(prior_state, list):\n",
        "            current_prior_state = (prior_state[0].clone(), prior_state[1].clone())\n",
        "        else:\n",
        "            current_prior_state = prior_state.clone()\n",
        "        return current_prior_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            result = (result0, result1)\n",
        "        else:\n",
        "            result = torch.cat(hidden, dim=0)\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.training or not self.save_eval_memory:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            x = inputs.transpose(2, 1).contiguous()\n",
        "            # New shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
        "            x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "            x = self.node2edge(x)\n",
        "            x = self.mlp2(x)\n",
        "            x_skip = x\n",
        "            x = self.edge2node(x)\n",
        "            x = self.mlp3(x)\n",
        "            x = self.node2edge(x)\n",
        "            x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "            x = self.mlp4(x)\n",
        "        \n",
        "            \n",
        "            # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "            # RNN aggregation\n",
        "            old_shape = x.shape\n",
        "            x = x.contiguous().view(-1, old_shape[2], old_shape[3])\n",
        "            forward_x, prior_state = self.forward_rnn(x)\n",
        "            timesteps = old_shape[2]\n",
        "            reverse_x = x.flip(1)\n",
        "            reverse_x, _ = self.reverse_rnn(reverse_x)\n",
        "            reverse_x = reverse_x.flip(1)\n",
        "            \n",
        "            #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "            prior_result = self.prior_fc_out(forward_x).view(old_shape[0], old_shape[1], timesteps, self.num_edges).transpose(1,2).contiguous()\n",
        "            combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "            encoder_result = self.encoder_fc_out(combined_x).view(old_shape[0], old_shape[1], timesteps, self.num_edges).transpose(1,2).contiguous()\n",
        "            return prior_result, encoder_result, prior_state\n",
        "        else:\n",
        "            # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "            num_timesteps = inputs.size(1)\n",
        "            all_x = []\n",
        "            all_forward_x = []\n",
        "            all_prior_result = []\n",
        "            prior_state = None\n",
        "            for timestep in range(num_timesteps):\n",
        "                x = inputs[:, timestep]\n",
        "                #x = inputs.transpose(2, 1).contiguous()\n",
        "                x = self.mlp1(x)  # 2-layer ELU net per node\n",
        "                x = self.node2edge(x)\n",
        "                x = self.mlp2(x)\n",
        "                x_skip = x\n",
        "                x = self.edge2node(x)\n",
        "                x = self.mlp3(x)\n",
        "                x = self.node2edge(x)\n",
        "                x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "                x = self.mlp4(x)\n",
        "            \n",
        "                \n",
        "                # At this point, x should be [batch, num_edges, num_timesteps, hidden_size]\n",
        "                # RNN aggregation\n",
        "                old_shape = x.shape\n",
        "                x = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "                forward_x, prior_state = self.forward_rnn(x, prior_state)\n",
        "                all_x.append(x.cpu())\n",
        "                all_forward_x.append(forward_x.cpu())\n",
        "                all_prior_result.append(self.prior_fc_out(forward_x).view(old_shape[0], 1, old_shape[1], self.num_edges).cpu())\n",
        "            reverse_state = None\n",
        "            all_encoder_result = []\n",
        "            for timestep in range(num_timesteps-1, -1, -1):\n",
        "                x = all_x[timestep].cuda()\n",
        "                reverse_x, reverse_state = self.reverse_rnn(x, reverse_state)\n",
        "                forward_x = all_forward_x[timestep].cuda()\n",
        "                \n",
        "                #x: [batch*num_edges, num_timesteps, hidden_size]\n",
        "                combined_x = torch.cat([forward_x, reverse_x], dim=-1)\n",
        "                all_encoder_result.append(self.encoder_fc_out(combined_x).view(inputs.size(0), 1, -1, self.num_edges))\n",
        "            prior_result = torch.cat(all_prior_result, dim=1).cuda(non_blocking=True)\n",
        "            encoder_result = torch.cat(all_encoder_result, dim=1).cuda(non_blocking=True)\n",
        "            return prior_result, encoder_result, prior_state\n",
        "\n",
        "    def single_step_forward(self, inputs, prior_state):\n",
        "        # Inputs is shape [batch, num_vars, input_size]\n",
        "        x = self.mlp1(inputs)  # 2-layer ELU net per node\n",
        "        x = self.node2edge(x)\n",
        "        x = self.mlp2(x)\n",
        "        x_skip = x\n",
        "        x = self.edge2node(x)\n",
        "        x = self.mlp3(x)\n",
        "        x = self.node2edge(x)\n",
        "        x = torch.cat((x, x_skip), dim=-1)  # Skip connection\n",
        "        x = self.mlp4(x)\n",
        "\n",
        "        old_shape = x.shape\n",
        "        x  = x.contiguous().view(-1, 1, old_shape[-1])\n",
        "        old_prior_shape = prior_state[0].shape\n",
        "        prior_state = (prior_state[0].view(1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]),\n",
        "                       prior_state[1].view(1, old_prior_shape[0]*old_prior_shape[1], old_prior_shape[2]))\n",
        "\n",
        "        x, prior_state = self.forward_rnn(x, prior_state)\n",
        "        prior_result = self.prior_fc_out(x).view(old_shape[0], old_shape[1], self.num_edges)\n",
        "        prior_state = (prior_state[0].view(old_prior_shape), prior_state[1].view(old_prior_shape))\n",
        "        return prior_result, prior_state\n",
        "\n",
        "    \n",
        "class DNRI_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_Decoder, self).__init__()\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "        input_size = params['input_size']\n",
        "        self.gpu = params['gpu']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2*n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, inputs, hidden, edges):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                        self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "            norm = float(len(self.msg_fc2)) - 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "            norm = float(len(self.msg_fc2))\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: to exclude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "            msg = msg * edges[:, :, i:i+1]\n",
        "            all_msgs += msg/norm\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden\n",
        "\n",
        "\n",
        "class DNRI_MLP_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_MLP_Decoder, self).__init__()\n",
        "        num_vars = params['num_vars']\n",
        "        edge_types = params['num_edge_types']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        msg_hid = params['decoder_hidden']\n",
        "        msg_out = msg_hid #TODO: make this a param\n",
        "        skip_first = params['skip_first']\n",
        "        n_in_node = params['input_size']\n",
        "\n",
        "        do_prob = params['decoder_dropout']\n",
        "        in_size = n_in_node\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2 * in_size, msg_hid) for _ in range(edge_types)])\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])\n",
        "        self.msg_out_shape = msg_out\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        out_size = n_in_node\n",
        "        self.out_fc1 = nn.Linear(in_size + msg_out, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "\n",
        "    def forward(self, inputs, hidden, edges):\n",
        "\n",
        "        # single_timestep_inputs has shape\n",
        "        # [batch_size, num_atoms, num_dims]\n",
        "\n",
        "        # single_timestep_rel_type has shape:\n",
        "        # [batch_size, num_atoms*(num_atoms-1), num_edge_types]\n",
        "        # Node2edge\n",
        "        receivers = inputs[:, self.recv_edges, :]\n",
        "        senders = inputs[:, self.send_edges, :]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        if inputs.is_cuda:\n",
        "            all_msgs = torch.cuda.FloatTensor(pre_msg.size(0), pre_msg.size(1),\n",
        "                                self.msg_out_shape).fill_(0.)\n",
        "        else:\n",
        "            all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                self.msg_out_shape)\n",
        "\n",
        "        if self.skip_first_edge_type:\n",
        "            start_idx = 1\n",
        "        else:\n",
        "            start_idx = 0\n",
        "        if self.training:\n",
        "            p = self.dropout_prob\n",
        "        else:\n",
        "            p = 0\n",
        "\n",
        "        # Run separate MLP for every edge type\n",
        "        # NOTE: To exlude one edge type, simply offset range by 1\n",
        "        for i in range(start_idx, len(self.msg_fc2)):\n",
        "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
        "            msg = F.dropout(msg, p=p)\n",
        "            msg = F.relu(self.msg_fc2[i](msg))\n",
        "            msg = msg * edges[:, :, i:i + 1]\n",
        "            all_msgs += msg\n",
        "\n",
        "        # Aggregate all msgs to receiver\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous()\n",
        "\n",
        "        # Skip connection\n",
        "        aug_inputs = torch.cat([inputs, agg_msgs], dim=-1)\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=p)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=p)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        # Predict position/velocity difference\n",
        "        return inputs + pred, None"
      ],
      "metadata": {
        "id": "iuQqExnLXtOC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class DNRI_DynamicVars(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_DynamicVars, self).__init__()\n",
        "        # Model Params\n",
        "        self.encoder = DNRI_DynamicVars_Encoder(params)\n",
        "        self.decoder = DNRI_DynamicVars_Decoder(params)\n",
        "        self.num_edge_types = params.get('num_edge_types')\n",
        "\n",
        "        # Training params\n",
        "        self.gumbel_temp = params.get('gumbel_temp')\n",
        "        self.train_hard_sample = params.get('train_hard_sample')\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "\n",
        "        self.normalize_kl = params.get('normalize_kl', False)\n",
        "        self.normalize_kl_per_var = params.get('normalize_kl_per_var', False)\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.kl_coef = params.get('kl_coef', 1.)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.timesteps = params.get('timesteps', 0)\n",
        "\n",
        "        self.burn_in_steps = params.get('train_burn_in_steps')\n",
        "        self.no_prior = params.get('no_prior', False)\n",
        "        self.avg_prior = params.get('avg_prior', False)\n",
        "        self.learned_prior = params.get('use_learned_prior', False)\n",
        "        self.anneal_teacher_forcing = params.get('anneal_teacher_forcing', False)\n",
        "        self.teacher_forcing_prior = params.get('teacher_forcing_prior', False)\n",
        "        self.steps = 0\n",
        "        self.gpu = params.get('gpu')\n",
        "\n",
        "    def get_graph_info(self, masks):\n",
        "        num_vars = masks.size(-1)\n",
        "        edges = torch.ones(num_vars, device=masks.device) - torch.eye(num_vars, device=masks.device)\n",
        "        tmp = torch.where(edges)\n",
        "        send_edges = tmp[0]\n",
        "        recv_edges = tmp[1]\n",
        "        tmp_inds = torch.tensor(list(range(num_vars)), device=masks.device, dtype=torch.long).unsqueeze_(1) #TODO: should initialize as long\n",
        "        edge2node_inds = (tmp_inds == recv_edges.unsqueeze(0)).nonzero()[:, 1].contiguous().view(-1, num_vars-1)\n",
        "        edge_masks = masks[:, :, send_edges]*masks[:, :, recv_edges] #TODO: gotta figure this one out still\n",
        "        return send_edges, recv_edges, edge2node_inds, edge_masks\n",
        "\n",
        "    def single_step_forward(self, inputs, node_masks, graph_info, decoder_hidden, edge_logits, hard_sample):\n",
        "        old_shape = edge_logits.shape\n",
        "        edges = model_utils.gumbel_softmax(\n",
        "            edge_logits.reshape(-1, self.num_edge_types), \n",
        "            tau=self.gumbel_temp, \n",
        "            hard=hard_sample).view(old_shape)\n",
        "        predictions, decoder_hidden = self.decoder(inputs, decoder_hidden, edges, node_masks, graph_info)\n",
        "        return predictions, decoder_hidden, edges\n",
        "\n",
        "\n",
        "    def normalize_inputs(self, inputs, node_masks):\n",
        "        return self.encoder.normalize_inputs(inputs, node_masks)\n",
        "\n",
        "    #profile\n",
        "    def calculate_loss(self, inputs, node_masks, node_inds, graph_info, is_train=False, teacher_forcing=True, return_edges=False, return_logits=False, use_prior_logits=False, normalized_inputs=None):\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_edges = []\n",
        "        all_predictions = []\n",
        "        all_priors = []\n",
        "        hard_sample = (not is_train) or self.train_hard_sample\n",
        "        prior_logits, posterior_logits, _ = self.encoder(inputs[:, :-1], node_masks[:, :-1], node_inds, graph_info, normalized_inputs)\n",
        "        if self.anneal_teacher_forcing:\n",
        "            teacher_forcing_steps = math.ceil((1 - self.train_percent)*num_time_steps)\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        edge_ind = 0\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            current_node_masks = node_masks[:, step]\n",
        "            node_inds = current_node_masks.nonzero()[:, -1]\n",
        "            num_edges = len(node_inds)*(len(node_inds)-1)\n",
        "            current_graph_info = graph_info[0][step]\n",
        "            if not use_prior_logits:\n",
        "                current_p_logits = posterior_logits[:, edge_ind:edge_ind+num_edges]\n",
        "            else:\n",
        "                current_p_logits = prior_logits[:, edge_ind:edge_ind+num_edges]\n",
        "            if self.gpu:\n",
        "                current_p_logits = current_p_logits.cuda(non_blocking=True)\n",
        "            edge_ind += num_edges\n",
        "            predictions, decoder_hidden, edges = self.single_step_forward(current_inputs, current_node_masks, current_graph_info, decoder_hidden, current_p_logits, hard_sample)\n",
        "            all_predictions.append(predictions)\n",
        "            all_edges.append(edges)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        target_masks = ((node_masks[:, :-1] == 1)*(node_masks[:, 1:] == 1)).float()\n",
        "        loss_nll = self.nll(all_predictions, target, target_masks)\n",
        "        prob = F.softmax(posterior_logits, dim=-1)\n",
        "        if self.gpu:\n",
        "            prob = prob.cuda(non_blocking=True)\n",
        "            prior_logits = prior_logits.cuda(non_blocking=True)\n",
        "        loss_kl = self.kl_categorical_learned(prob, prior_logits)\n",
        "        loss = loss_nll + self.kl_coef*loss_kl\n",
        "        loss = loss.mean()\n",
        "        if return_edges:\n",
        "            return loss, loss_nll, loss_kl, edges\n",
        "        elif return_logits:\n",
        "            return loss, loss_nll, loss_kl, posterior_logits, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def get_prior_posterior(self, inputs, student_force=False, burn_in_steps=None):\n",
        "        self.eval()\n",
        "        posterior_logits = self.encoder(inputs)\n",
        "        posterior_probs = torch.softmax(posterior_logits, dim=-1)\n",
        "        prior_hidden = self.prior_model.get_initial_hidden(inputs)\n",
        "        all_logits = []\n",
        "        if student_force:\n",
        "            decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "            for step in range(burn_in_steps):\n",
        "                current_inputs= inputs[:, step]\n",
        "                predictions, prior_hidden, decoder_hidden, _, prior_logits = self.single_step_forward(current_inputs, prior_hidden, decoder_hidden, None, True)\n",
        "                all_logits.append(prior_logits)\n",
        "            for step in range(inputs.size(1) - burn_in_steps):\n",
        "                predictions, prior_hidden, decoder_hidden, _, prior_logits = self.single_step_forward(predictions, prior_hidden, decoder_hidden, None, True)\n",
        "                all_logits.append(prior_logits)\n",
        "        else:\n",
        "            for step in range(inputs.size(1)):\n",
        "                current_inputs = inputs[:, step]\n",
        "                prior_logits, prior_hidden = self.prior_model(prior_hidden, current_inputs)\n",
        "                all_logits.append(prior_logits)\n",
        "        logits = torch.stack(all_logits, dim=1)\n",
        "        prior_probs = torch.softmax(logits, dim=-1)\n",
        "        return prior_probs, posterior_probs\n",
        "\n",
        "    def get_edge_probs(self, inputs):\n",
        "        self.eval()\n",
        "        prior_hidden = self.prior_model.get_initial_hidden(inputs)\n",
        "        all_logits = []\n",
        "        for step in range(inputs.size(1)):\n",
        "            current_inputs = inputs[:, step]\n",
        "            prior_logits, prior_hidden = self.prior_model(prior_hidden, current_inputs)\n",
        "            all_logits.append(prior_logits)\n",
        "        logits = torch.stack(all_logits, dim=1)\n",
        "        edge_probs = torch.softmax(logits, dim=-1)\n",
        "        return edge_probs\n",
        "\n",
        "    def predict_future(self, inputs, masks, node_inds, graph_info, burn_in_masks):\n",
        "        '''\n",
        "        Here, we assume the following:\n",
        "        * inputs contains all of the gt inputs, including for the time steps we're predicting\n",
        "        * masks keeps track of the variables that are being tracked\n",
        "        * burn_in_masks is set to 1 whenever we're supposed to feed in that variable's state\n",
        "          for a given time step\n",
        "        '''\n",
        "        total_timesteps = inputs.size(1)\n",
        "        prior_hidden = self.encoder.get_initial_hidden(inputs)\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        predictions = inputs[:, 0]\n",
        "        preds = []\n",
        "        for step in range(total_timesteps-1):\n",
        "            current_masks = masks[:, step]\n",
        "            current_burn_in_masks = burn_in_masks[:, step].unsqueeze(-1).type(inputs.dtype)\n",
        "            current_inps = inputs[:, step]\n",
        "            current_node_inds = node_inds[0][step] #TODO: check what's passed in here\n",
        "            current_graph_info = graph_info[0][step]\n",
        "            encoder_inp = current_burn_in_masks*current_inps + (1-current_burn_in_masks)*predictions\n",
        "            current_edge_logits, prior_hidden = self.encoder.single_step_forward(encoder_inp, current_masks, current_node_inds, current_graph_info, prior_hidden)\n",
        "            predictions, decoder_hidden, _ = self.single_step_forward(encoder_inp, current_masks, current_graph_info, decoder_hidden, current_edge_logits, True)\n",
        "            preds.append(predictions)\n",
        "        return torch.stack(preds, dim=1)\n",
        "\n",
        "    def copy_states(self, prior_state, decoder_state):\n",
        "        if isinstance(prior_state, tuple) or isinstance(prior_state, list):\n",
        "            current_prior_state = (prior_state[0].clone(), prior_state[1].clone())\n",
        "        else:\n",
        "            current_prior_state = prior_state.clone()\n",
        "        if isinstance(decoder_state, tuple) or isinstance(decoder_state, list):\n",
        "            current_decoder_state = (decoder_state[0].clone(), decoder_state[1].clone())\n",
        "        else:\n",
        "            current_decoder_state = decoder_state.clone()\n",
        "        return current_prior_state, current_decoder_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size):\n",
        "        if self.fix_encoder_alignment:\n",
        "            prior_logits, _, prior_hidden = self.encoder(inputs)\n",
        "        else:\n",
        "            prior_logits, _, prior_hidden = self.encoder(inputs[:, :-1])\n",
        "        decoder_hidden = self.decoder.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            current_edge_logits = prior_logits[:, step]\n",
        "            predictions, decoder_hidden, _ = self.single_step_forward(current_inputs, decoder_hidden, current_edge_logits, True)\n",
        "        all_timestep_preds = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            prior_states = []\n",
        "            decoder_states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step] \n",
        "                current_edge_logits, prior_hidden = self.encoder.single_step_forward(predictions, prior_hidden)\n",
        "                predictions, decoder_hidden, _ = self.single_step_forward(predictions, decoder_hidden, current_edge_logits, True)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_prior, tmp_decoder = self.copy_states(prior_hidden, decoder_hidden)\n",
        "                prior_states.append(tmp_prior)\n",
        "                decoder_states.append(tmp_decoder)\n",
        "            batch_prior_hidden = self.merge_hidden(prior_states)\n",
        "            batch_decoder_hidden = self.merge_hidden(decoder_states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_edge_logits, batch_prior_hidden = self.encoder.single_step_forward(current_batch_preds, batch_prior_hidden)\n",
        "                current_batch_preds, batch_decoder_hidden, _ = self.single_step_forward(current_batch_preds, batch_decoder_hidden, current_batch_edge_logits, True)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "        result =  torch.cat(all_timestep_preds, dim=0)\n",
        "        return result.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target, masks):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target, masks)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target, masks)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target, masks)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, masks, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))*masks.unsqueeze(-1)\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            raise NotImplementedError()\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const*masks).view(preds.size(0), -1).sum(dim=-1)/(masks.view(masks.size(0), -1).sum(dim=1)+1e-8)\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target, masks):\n",
        "        if self.normalize_nll:\n",
        "            loss = nn.BCEWithLogitsLoss(reduction='none')(preds, target)\n",
        "            return (loss*masks.unsqueeze(-1)).view(preds.size(0), -1).sum(dim=-1)/(masks.view(masks.size(0), -1).sum(dim=1))\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def nll_poisson(self, preds, target, masks):\n",
        "        if self.normalize_nll:\n",
        "            loss = nn.PoissonNLLLoss(reduction='none')(preds, target)\n",
        "            return (loss*masks.unsqueeze(-1)).view(preds.size(0), -1).sum(dim=-1)/(masks.view(masks.size(0), -1).sum(dim=1))\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def kl_categorical_learned(self, preds, prior_logits):\n",
        "        log_prior = nn.LogSoftmax(dim=-1)(prior_logits)\n",
        "        kl_div = preds*(torch.log(preds + 1e-16) - log_prior)\n",
        "        if self.normalize_kl:     \n",
        "            return kl_div.sum(-1).view(preds.size(0), -1).mean(dim=1)\n",
        "        elif self.normalize_kl_per_var:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "class DNRI_DynamicVars_Encoder(nn.Module):\n",
        "    # Here, encoder also produces prior\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_DynamicVars_Encoder, self).__init__()\n",
        "        self.num_edges = params['num_edge_types']\n",
        "        self.smooth_graph = params.get('smooth_graph', False)\n",
        "        self.gpu_parallel = params.get('gpu_parallel', False)\n",
        "        self.pool_edges = params.get('pool_edges', False)\n",
        "        self.separate_prior_encoder = params.get('separate_prior_encoder', False)\n",
        "        self.gpu = params.get('gpu')\n",
        "        no_bn = params['no_encoder_bn']\n",
        "        dropout = params['encoder_dropout']\n",
        "\n",
        "        hidden_size = params['encoder_hidden']\n",
        "        self.rnn_hidden_size = rnn_hidden_size = params['encoder_rnn_hidden']\n",
        "        rnn_type = params['encoder_rnn_type']\n",
        "        inp_size = params['input_size']\n",
        "        self.mlp1 = RefNRIMLP(inp_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp2 = RefNRIMLP(hidden_size * 2, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp3 = RefNRIMLP(hidden_size, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.mlp4 = RefNRIMLP(hidden_size * 3, hidden_size, hidden_size, dropout, no_bn=no_bn)\n",
        "        self.train_data_len = params.get('train_data_len', -1)\n",
        "\n",
        "        if rnn_hidden_size is None:\n",
        "            rnn_hidden_size = hidden_size\n",
        "        if rnn_type == 'lstm':\n",
        "            self.forward_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.LSTM(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        elif rnn_type == 'gru':\n",
        "            self.forward_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "            self.reverse_rnn = nn.GRU(hidden_size, rnn_hidden_size, batch_first=True)\n",
        "        out_hidden_size = 2*rnn_hidden_size\n",
        "        num_layers = params['encoder_mlp_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.encoder_fc_out = nn.Linear(out_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['encoder_mlp_hidden']\n",
        "            layers = [nn.Linear(out_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.encoder_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        num_layers = params['prior_num_layers']\n",
        "        if num_layers == 1:\n",
        "            self.prior_fc_out = nn.Linear(rnn_hidden_size, self.num_edges)\n",
        "        else:\n",
        "            tmp_hidden_size = params['prior_hidden_size']\n",
        "            layers = [nn.Linear(rnn_hidden_size, tmp_hidden_size), nn.ELU(inplace=True)]\n",
        "            for _ in range(num_layers - 2):\n",
        "                layers.append(nn.Linear(tmp_hidden_size, tmp_hidden_size))\n",
        "                layers.append(nn.ELU(inplace=True))\n",
        "            layers.append(nn.Linear(tmp_hidden_size, self.num_edges))\n",
        "            self.prior_fc_out = nn.Sequential(*layers)\n",
        "\n",
        "        self.normalize_mode = params['encoder_normalize_mode']\n",
        "        if self.normalize_mode == 'normalize_inp':\n",
        "            self.bn = nn.BatchNorm1d(inp_size)\n",
        "        # Possible options: None, 'normalize_inp', 'normalize_all'\n",
        "\n",
        "        self.init_weights()\n",
        "        \n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "    def node2edge(self, node_embeddings, send_edges, recv_edges):\n",
        "        #node_embeddings: [batch, num_nodes, embed_size]\n",
        "        send_embed = node_embeddings[:, send_edges, :]\n",
        "        recv_embed = node_embeddings[:, recv_edges, :]\n",
        "        return torch.cat([send_embed, recv_embed], dim=-1) \n",
        "\n",
        "    def edge2node(self, edge_embeddings, edge2node_inds, num_vars):\n",
        "        incoming = edge_embeddings[:, edge2node_inds[:, 0], :].clone()\n",
        "        for i in range(1, edge2node_inds.size(1)):\n",
        "            incoming += edge_embeddings[:, edge2node_inds[:, i]]\n",
        "        return incoming/(num_vars-1)\n",
        "    \n",
        "    def get_initial_hidden(self, inputs):\n",
        "        batch = inputs.size(0)*inputs.size(2)*(inputs.size(2)-1)\n",
        "        hidden = torch.zeros(1, batch, self.rnn_hidden_size, device=inputs.device)\n",
        "        cell = torch.zeros(1, batch, self.rnn_hidden_size, device=inputs.device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def batch_node2edge(self, x, send_edges, recv_edges):\n",
        "        send_embed = x[send_edges]\n",
        "        recv_embed = x[recv_edges]\n",
        "        return torch.cat([send_embed, recv_embed], dim=-1)\n",
        "\n",
        "    def batch_edge2node(self, x, result_shape, recv_edges):\n",
        "        result = torch.zeros(result_shape, device=x.device)\n",
        "        result.index_add_(0, recv_edges, x)\n",
        "        return result\n",
        "\n",
        "    def normalize_inputs(self, inputs, node_masks):\n",
        "        if self.normalize_mode == 'normalize_inp':\n",
        "            raise NotImplementedError\n",
        "        elif self.normalize_mode == 'normalize_all':\n",
        "            result = self.compute_feat_transform(inputs, node_masks)\n",
        "        return result\n",
        "\n",
        "    def compute_feat_transform(self, inputs, node_masks):\n",
        "        # The following is to ensure we don't run on a sequence that's too long at once\n",
        "        if len(inputs.shape) == 3:\n",
        "            inputs = inputs.unsqueeze(0)\n",
        "            node_masks = node_masks.unsqueeze(0)\n",
        "        inp_list = inputs.split(self.train_data_len, dim=1)\n",
        "        node_masks_list = node_masks.split(self.train_data_len, dim=1)\n",
        "        final_result = [[] for _ in range(inputs.size(0))]\n",
        "        count = 0\n",
        "        for inputs, node_masks in zip(inp_list, node_masks_list):\n",
        "            if not self.training:\n",
        "                #print(\"IND %d OF %d\"%(count, len(node_masks_list)))\n",
        "                count += 1\n",
        "            flat_masks = node_masks.nonzero(as_tuple=True)\n",
        "            batch_num_vars = (node_masks != 0).sum(dim=-1)\n",
        "            num_vars = batch_num_vars.view(-1)\n",
        "            #TODO: is it faster to put this on cpu or gpu?\n",
        "            edge_info = [torch.where(torch.ones(nvar, device=num_vars.device) - torch.eye(nvar, device=num_vars.device)) for nvar in num_vars]\n",
        "            offsets = torch.cat([torch.tensor([0], dtype=torch.long, device=num_vars.device), num_vars.cumsum(0)[:-1]])\n",
        "            send_edges = torch.cat([l[0] + offset for l,offset in zip(edge_info, offsets)])\n",
        "            recv_edges = torch.cat([l[1] + offset for l, offset in zip(edge_info, offsets)])\n",
        "            \n",
        "            flat_inp = inputs[flat_masks]\n",
        "            tmp_batch = flat_inp.size(0)\n",
        "            x = self.mlp1(flat_inp)\n",
        "            x = self.batch_node2edge(x, send_edges, recv_edges)\n",
        "            x = self.mlp2(x)\n",
        "            x_skip = x\n",
        "            result_shape = (tmp_batch, x.size(-1))\n",
        "            x = self.batch_edge2node(x, result_shape, recv_edges)\n",
        "            x = self.mlp3(x)\n",
        "            x = self.batch_node2edge(x, send_edges, recv_edges)\n",
        "            x = torch.cat([x, x_skip], dim=-1)\n",
        "            x = self.mlp4(x)\n",
        "            # TODO: extract into batch-wise structure\n",
        "            num_edges = batch_num_vars*(batch_num_vars-1)\n",
        "            num_edges = num_edges.sum(dim=-1)\n",
        "            #if not self.training:\n",
        "            #    x = x.cpu()\n",
        "            batched_result = x.split(num_edges.tolist())\n",
        "            for ind,tmp_result in enumerate(batched_result):\n",
        "                final_result[ind].append(tmp_result)\n",
        "        final_result = [torch.cat(tmp_result) for tmp_result in final_result]\n",
        "        return final_result\n",
        "\n",
        "    def forward(self, inputs, node_masks, all_node_inds, all_graph_info, normalized_inputs=None):\n",
        "        if inputs.size(0) > 1:\n",
        "            raise ValueError(\"Batching during forward not currently supported\")\n",
        "        if self.normalize_mode == 'normalize_all':\n",
        "            if normalized_inputs is not None:\n",
        "                x = torch.cat(normalized_inputs, dim=0)\n",
        "            else:\n",
        "                x = torch.cat(self.normalize_inputs(inputs, node_masks), dim=0)\n",
        "        else:\n",
        "            # Right now, we'll always want to do this\n",
        "            raise NotImplementedError\n",
        "        # Inputs is shape [batch, num_timesteps, num_vars, input_size]\n",
        "        num_timesteps = node_masks.size(1)\n",
        "        max_num_vars = inputs.size(2)\n",
        "        max_num_edges = max_num_vars*(max_num_vars-1)\n",
        "        forward_state = (torch.zeros(1, max_num_edges, self.rnn_hidden_size, device=inputs.device),\n",
        "                         torch.zeros(1, max_num_edges, self.rnn_hidden_size, device=inputs.device))\n",
        "        reverse_state = (torch.zeros(1, max_num_edges, self.rnn_hidden_size, device=inputs.device),\n",
        "                         torch.zeros(1, max_num_edges, self.rnn_hidden_size, device=inputs.device))\n",
        "        all_x = []\n",
        "        all_forward_states = []\n",
        "        all_reverse_states = [] \n",
        "        prior_results = []\n",
        "        x_ind = 0\n",
        "        for timestep in range(num_timesteps):\n",
        "            current_node_masks = node_masks[:, timestep]\n",
        "            node_inds = all_node_inds[0][timestep]\n",
        "            if self.gpu:\n",
        "                node_inds = node_inds.cuda(non_blocking=True)\n",
        "            if len(node_inds) <= 1:\n",
        "                all_forward_states.append(torch.empty(1, 0, self.rnn_hidden_size, device=inputs.device))\n",
        "                all_x.append(None)\n",
        "                continue\n",
        "            send_edges, recv_edges, _ = all_graph_info[0][timestep]\n",
        "            if self.gpu:\n",
        "                send_edges, recv_edges = send_edges.cuda(non_blocking=True), recv_edges.cuda(non_blocking=True)\n",
        "            global_send_edges = node_inds[send_edges]\n",
        "            global_recv_edges = node_inds[recv_edges]\n",
        "            global_edge_inds = global_send_edges*(max_num_vars-1) + global_recv_edges - (global_recv_edges >= global_send_edges).long()\n",
        "            current_x = x[x_ind:x_ind+len(global_send_edges)]\n",
        "            if self.gpu:\n",
        "                current_x = current_x.cuda(non_blocking=True)\n",
        "            x_ind += len(global_send_edges)\n",
        "\n",
        "            old_shape = current_x.shape\n",
        "            current_x = current_x.view(old_shape[-2], 1, old_shape[-1])\n",
        "            current_state = (forward_state[0][:, global_edge_inds], forward_state[1][:, global_edge_inds])\n",
        "            current_x, current_state = self.forward_rnn(current_x, current_state)\n",
        "            tmp_state0 = forward_state[0].clone()\n",
        "            tmp_state0[:, global_edge_inds] = current_state[0]\n",
        "            tmp_state1 = forward_state[1].clone()\n",
        "            tmp_state1[:, global_edge_inds] = current_state[1]\n",
        "            all_forward_states.append(current_state[0])\n",
        "\n",
        "        # Reverse pass\n",
        "        encoder_results = []\n",
        "        x_ind = x.size(0)\n",
        "        for timestep in range(num_timesteps-1, -1, -1):\n",
        "            current_node_masks = node_masks[:, timestep]\n",
        "            node_inds = all_node_inds[0][timestep]\n",
        "            if self.gpu:\n",
        "                node_inds = node_inds.cuda(non_blocking=True)\n",
        "\n",
        "            if len(node_inds) <= 1:\n",
        "                continue\n",
        "            send_edges, recv_edges, _ = all_graph_info[0][timestep]\n",
        "            if self.gpu:\n",
        "                send_edges, recv_edges = send_edges.cuda(non_blocking=True), recv_edges.cuda(non_blocking=True)\n",
        "            global_send_edges = node_inds[send_edges]\n",
        "            global_recv_edges = node_inds[recv_edges]\n",
        "            global_edge_inds = global_send_edges*(max_num_vars-1) + global_recv_edges - (global_recv_edges >= global_send_edges).long()\n",
        "            current_x = x[x_ind-len(global_send_edges):x_ind]\n",
        "            if self.gpu:\n",
        "                current_x = current_x.cuda(non_blocking=True)\n",
        "            x_ind -= len(global_send_edges)\n",
        "            old_shape = current_x.shape\n",
        "            current_x = current_x.view(old_shape[-2], 1, old_shape[-1])\n",
        "\n",
        "            current_state = (reverse_state[0][:, global_edge_inds], reverse_state[1][:, global_edge_inds])\n",
        "            current_x, current_state = self.reverse_rnn(current_x, current_state)\n",
        "\n",
        "            tmp_state0 = reverse_state[0].clone()\n",
        "            tmp_state0[:, global_edge_inds] = current_state[0]\n",
        "            tmp_state1 = reverse_state[1].clone()\n",
        "            tmp_state1[:, global_edge_inds] = current_state[1]\n",
        "            all_reverse_states.append(current_state[0])\n",
        "        all_forward_states = torch.cat(all_forward_states, dim=1)\n",
        "        all_reverse_states = torch.cat(all_reverse_states, dim=1).flip(1)\n",
        "        all_states = torch.cat([all_forward_states, all_reverse_states], dim=-1)\n",
        "        prior_result = self.prior_fc_out(all_forward_states)\n",
        "        encoder_result = self.encoder_fc_out(all_states)\n",
        "        return prior_result, encoder_result, forward_state\n",
        "        \n",
        "    def single_step_forward(self, inputs, node_masks, node_inds, all_graph_info, forward_state):\n",
        "        if self.normalize_mode == 'normalize_all':\n",
        "            x = self.normalize_inputs(inputs, node_masks)[0]\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        # Inputs is shape [batch, num_vars, input_size]\n",
        "        max_num_vars = inputs.size(1)\n",
        "        max_num_edges = max_num_vars*(max_num_vars-1)\n",
        "        if len(node_inds) > 1:\n",
        "            send_edges, recv_edges, _ = all_graph_info\n",
        "            global_send_edges = node_inds[send_edges]\n",
        "            global_recv_edges = node_inds[recv_edges]\n",
        "            global_edge_inds = global_send_edges*(max_num_vars-1) + global_recv_edges - (global_recv_edges >= global_send_edges).long()\n",
        "            old_shape = x.shape\n",
        "            x = x.view(old_shape[-2], 1, old_shape[-1])\n",
        "            current_state = (forward_state[0][:, global_edge_inds], forward_state[1][:, global_edge_inds])\n",
        "            x, current_state = self.forward_rnn(x, current_state)\n",
        "            tmp_state0 = forward_state[0].clone()\n",
        "            tmp_state0[:, global_edge_inds] = current_state[0]\n",
        "            tmp_state1 = forward_state[1].clone()\n",
        "            tmp_state1[:, global_edge_inds] = current_state[1]\n",
        "            forward_state = (tmp_state0, tmp_state1)\n",
        "            prior_result = self.prior_fc_out(current_state[0])\n",
        "        else:\n",
        "            prior_result = torch.empty(1, 0, self.num_edges)\n",
        "\n",
        "        return prior_result, forward_state\n",
        "\n",
        "\n",
        "class DNRI_DynamicVars_Decoder(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(DNRI_DynamicVars_Decoder, self).__init__()\n",
        "        input_size = params['input_size']\n",
        "        self.gpu = params['gpu']\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "\n",
        "        self.msg_fc1 = nn.ModuleList(\n",
        "            [nn.Linear(2*n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_fc2 = nn.ModuleList(\n",
        "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)]\n",
        "        )\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "        \n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "        \n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "                m.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, inputs, hidden, edges, node_masks, graph_info):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, current_num_edges, num_edge_types]\n",
        "\n",
        "        max_num_vars = inputs.size(1)\n",
        "        node_inds = node_masks.nonzero()[:, -1]\n",
        "\n",
        "        current_hidden = hidden[:, node_inds]\n",
        "        current_inputs = inputs[:, node_inds]\n",
        "        num_vars = current_hidden.size(1)\n",
        "        \n",
        "        if num_vars > 1:\n",
        "            send_edges, recv_edges, edge2node_inds = graph_info\n",
        "            if self.gpu:\n",
        "                send_edges, recv_edges, edge2node_inds = send_edges.cuda(non_blocking=True), recv_edges.cuda(non_blocking=True), edge2node_inds.cuda(non_blocking=True)\n",
        "            global_send_edges = node_inds[send_edges]\n",
        "            global_recv_edges = node_inds[recv_edges]\n",
        "            receivers = current_hidden[:, recv_edges]\n",
        "            senders = current_hidden[:, send_edges]\n",
        "            # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "            pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "            all_msgs = torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
        "                                            self.msg_out_shape, device=inputs.device)\n",
        "            if self.skip_first_edge_type:\n",
        "                start_idx = 1\n",
        "                norm = float(len(self.msg_fc2)) - 1\n",
        "            else:\n",
        "                start_idx = 0\n",
        "                norm = float(len(self.msg_fc2))\n",
        "\n",
        "            # Run separate MLP for every edge type\n",
        "            # NOTE: to exclude one edge type, simply offset range by 1\n",
        "            for i in range(start_idx, len(self.msg_fc2)):\n",
        "                msg = torch.tanh(self.msg_fc1[i](pre_msg))\n",
        "                msg = F.dropout(msg, p=self.dropout_prob)\n",
        "                msg = torch.tanh(self.msg_fc2[i](msg))\n",
        "                msg = msg * edges[:, :, i:i+1]\n",
        "                all_msgs += msg/norm\n",
        "\n",
        "            incoming = all_msgs[:, edge2node_inds[:, 0], :].clone()\n",
        "            for i in range(1, edge2node_inds.size(1)):\n",
        "                incoming += all_msgs[:, edge2node_inds[:, i], :]\n",
        "            agg_msgs = incoming/(num_vars-1)\n",
        "        elif num_vars == 0:\n",
        "            pred_all = torch.zeros(inputs.size(0), max_num_vars, inputs.size(-1), device=inputs.device)\n",
        "            return pred_all, hidden\n",
        "        else:\n",
        "            agg_msgs = torch.zeros(current_inputs.size(0), num_vars, self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(current_inputs).view(current_inputs.size(0), num_vars, -1)\n",
        "        inp_i = self.input_i(current_inputs).view(current_inputs.size(0), num_vars, -1)\n",
        "        inp_n = self.input_n(current_inputs).view(current_inputs.size(0), num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        current_hidden = (1 - i)*n + i*current_hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(current_hidden)), p=self.dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = current_inputs + pred\n",
        "        hidden = hidden.clone()\n",
        "        hidden[:, node_inds] = current_hidden\n",
        "        pred_all = torch.zeros(inputs.size(0), max_num_vars, inputs.size(-1), device=inputs.device)\n",
        "        pred_all[0, node_inds] = pred\n",
        "\n",
        "        return pred_all, hidden"
      ],
      "metadata": {
        "id": "FN9zDCWEYNzW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class RecurrentBaseline(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(RecurrentBaseline, self).__init__()\n",
        "        self.num_vars = params['num_vars']\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.anneal_teacher_forcing = params.get('anneal_teacher_forcing', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.kl_coef = 0\n",
        "        self.steps = 0\n",
        "    \n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def normalize_inputs(self, inputs):\n",
        "        return inputs\n",
        "    \n",
        "    def calculate_loss(self, inputs, is_train=False, teacher_forcing=True, return_logits=False, use_prior_logits=False, normalized_inputs=None):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_predictions = []\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        loss_nll = self.nll(all_predictions, target)\n",
        "        loss_kl = torch.zeros_like(loss_nll)\n",
        "        loss = loss_nll.mean()\n",
        "        if return_logits:\n",
        "            return loss, loss_nll, loss_kl, None, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, prediction_steps, return_everything=False):\n",
        "        burn_in_timesteps = inputs.size(1)\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        all_predictions = []\n",
        "        for step in range(burn_in_timesteps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "            if return_everything:\n",
        "                all_predictions.append(predictions)\n",
        "        predictions = inputs[:, burn_in_timesteps-1]\n",
        "        for step in range(prediction_steps):\n",
        "            predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        \n",
        "        predictions = torch.stack(all_predictions, dim=1)\n",
        "        return predictions\n",
        "\n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "        all_timestep_preds = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step]\n",
        "                predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_decoder = self.copy_states(hidden)\n",
        "                states.append(tmp_decoder)\n",
        "            batch_hidden = self.merge_hidden(states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_preds, batch_hidden = self.single_step_forward(current_batch_preds, batch_hidden)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "        results = torch.cat(all_timestep_preds, dim=0)\n",
        "        return results.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            return neg_log_p.sum() / (target.size(0) * target.size(2))\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return neg_log_p.view(target.size(0), -1).sum() / (target.size(1))\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.BCEWithLogitsLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def nll_poisson(self, preds, target):\n",
        "        if self.normalize_nll:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).mean(dim=1)\n",
        "        else:\n",
        "            return nn.PoissonNLLLoss(reduction='none')(preds, target).view(preds.size(0), -1).sum(dim=1)\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "class SingleRNNBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(SingleRNNBaseline, self).__init__(params)\n",
        "        self.n_hid = n_hid = params['decoder_hidden']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "        self.num_vars = num_vars = params['num_vars']\n",
        "        self.rnn_type = params['decoder_rnn_type']\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTMCell(input_size, n_hid)\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRUCell(input_size, n_hid)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, out_size),\n",
        "        )\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "        '''\n",
        "        if self.rnn_type == 'lstm':\n",
        "            raise NotImplementedError\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        else:\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        '''\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        tmp_inp = inputs.reshape(-1, inputs.size(-1))\n",
        "        hidden = self.rnn(tmp_inp)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            tmp = hidden[0].view(inputs.size(0), inputs.size(1), -1)\n",
        "        else:\n",
        "            tmp = hidden.view(inputs.size(0), inputs.size(1), -1)\n",
        "        outputs = inputs + self.out(tmp)\n",
        "        return outputs, hidden\n",
        "\n",
        "class JointRNNBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(JointRNNBaseline, self).__init__(params)\n",
        "        self.n_hid = n_hid = params['decoder_hidden']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        self.num_vars = num_vars = params['num_vars']\n",
        "        out_size = input_size = params['input_size']*num_vars\n",
        "        self.rnn_type = params['decoder_rnn_type']\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTMCell(input_size, n_hid)\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRUCell(input_size, n_hid)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, n_hid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(do_prob),\n",
        "            nn.Linear(n_hid, out_size),\n",
        "        )\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return None\n",
        "        '''\n",
        "        if self.rnn_type == 'lstm':\n",
        "            raise NotImplementedError\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        else:\n",
        "            return torch.zeros(inputs.size(0)*inputs.size(2), self.n_hid, device=inputs.device)\n",
        "        '''\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        tmp_inp = inputs.view(inputs.size(0), -1)\n",
        "        hidden = self.rnn(tmp_inp)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            tmp = hidden[0]\n",
        "        else:\n",
        "            tmp = hidden\n",
        "        outputs = inputs + self.out(tmp).view(inputs.size(0), inputs.size(1), -1)\n",
        "        return outputs, hidden\n",
        " \n",
        "        \n",
        "\n",
        "\n",
        "class FullyConnectedBaseline(RecurrentBaseline):\n",
        "    def __init__(self, params):\n",
        "        super(FullyConnectedBaseline, self).__init__(params)\n",
        "        n_hid = params['decoder_hidden']\n",
        "        edge_types = params['num_edge_types']\n",
        "        skip_first = params['skip_first']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "        self.num_vars = num_vars =  params['num_vars']\n",
        "\n",
        "        self.msg_fc1 = nn.Linear(2*n_hid, n_hid)\n",
        "        self.msg_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.msg_out_shape = n_hid\n",
        "        self.skip_first_edge_type = skip_first\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "        self.num_vars = num_vars\n",
        "        edges = np.ones(num_vars) - np.eye(num_vars)\n",
        "        self.send_edges = np.where(edges)[0]\n",
        "        self.recv_edges = np.where(edges)[1]\n",
        "        self.edge2node_mat = nn.Parameter(torch.FloatTensor(encode_onehot(self.recv_edges)), requires_grad=False)\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "\n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        # node2edge\n",
        "        receivers = hidden[:, self.recv_edges, :]\n",
        "        senders = hidden[:, self.send_edges, :]\n",
        "\n",
        "        # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "        pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "        msg = torch.tanh(self.msg_fc1(pre_msg))\n",
        "        msg = F.dropout(msg, p=dropout_prob)\n",
        "        msg = torch.tanh(self.msg_fc2(msg))\n",
        "        all_msgs = msg\n",
        "\n",
        "        # This step sums all of the messages per node\n",
        "        agg_msgs = all_msgs.transpose(-2, -1).matmul(self.edge2node_mat).transpose(-2, -1)\n",
        "        agg_msgs = agg_msgs.contiguous() / (self.num_vars - 1) # Average\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_i = self.input_i(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        inp_n = self.input_n(inputs).view(inputs.size(0), self.num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        hidden = (1 - i)*n + i*hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = inputs + pred\n",
        "\n",
        "        return pred, hidden"
      ],
      "metadata": {
        "id": "0dNYWfZaYpMo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class RecurrentBaseline_DynamicVars(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(RecurrentBaseline_DynamicVars, self).__init__()\n",
        "        self.teacher_forcing_steps = params.get('teacher_forcing_steps', -1)\n",
        "        self.nll_loss_type = params.get('nll_loss_type', 'crossent')\n",
        "        self.prior_variance = params.get('prior_variance')\n",
        "        self.normalize_nll = params.get('normalize_nll', False)\n",
        "        self.normalize_nll_per_var = params.get('normalize_nll_per_var', False)\n",
        "        self.anneal_teacher_forcing = params.get('anneal_teacher_forcing', False)\n",
        "        self.val_teacher_forcing_steps = params.get('val_teacher_forcing_steps', -1)\n",
        "        self.kl_coef = 0\n",
        "        self.steps = 0\n",
        "    \n",
        "    def single_step_forward(self, inputs, hidden):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def normalize_inputs(self, inputs, masks):\n",
        "        return inputs\n",
        "    \n",
        "    def calculate_loss(self, inputs, node_masks, node_inds, graph_info, is_train=False, teacher_forcing=True, return_logits=False, use_prior_logits=False, normalized_inputs=None):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        num_time_steps = inputs.size(1)\n",
        "        all_predictions = []\n",
        "        if not is_train:\n",
        "            teacher_forcing_steps = self.val_teacher_forcing_steps\n",
        "        else:\n",
        "            teacher_forcing_steps = self.teacher_forcing_steps\n",
        "        for step in range(num_time_steps-1):\n",
        "            if (teacher_forcing and (teacher_forcing_steps == -1 or step < teacher_forcing_steps)) or step == 0:\n",
        "                current_inputs = inputs[:, step]\n",
        "            else:\n",
        "                current_inputs = predictions\n",
        "            current_node_masks = node_masks[:, step]\n",
        "            node_inds = current_node_masks.nonzero()[:, -1]\n",
        "            num_edges = len(node_inds)*(len(node_inds)-1)\n",
        "            current_graph_info = graph_info[0][step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, current_node_masks, current_graph_info, hidden)\n",
        "            all_predictions.append(predictions)\n",
        "        all_predictions = torch.stack(all_predictions, dim=1)\n",
        "        target = inputs[:, 1:, :, :]\n",
        "        target_masks = ((node_masks[:, :-1] == 1)*(node_masks[:, 1:] == 1)).float()\n",
        "        loss_nll = self.nll(all_predictions, target, target_masks)\n",
        "        loss_kl = torch.zeros_like(loss_nll)\n",
        "        loss = loss_nll.mean()\n",
        "        if return_logits:\n",
        "            return loss, loss_nll, loss_kl, None, all_predictions\n",
        "        else:\n",
        "            return loss, loss_nll, loss_kl\n",
        "\n",
        "    def predict_future(self, inputs, masks, node_inds, graph_info, burn_in_masks):\n",
        "        '''\n",
        "        Here, we assume the following:\n",
        "        * inputs contains all of the gt inputs, including for the time steps we're predicting\n",
        "        * masks keeps track of the variables that are being tracked\n",
        "        * burn_in_masks is set to 1 whenever we're supposed to feed in that variable's state\n",
        "          for a given time step\n",
        "        '''\n",
        "        total_timesteps = inputs.size(1)\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        predictions = inputs[:, 0]\n",
        "        preds = []\n",
        "        for step in range(total_timesteps-1):\n",
        "            current_masks = masks[:, step]\n",
        "            current_burn_in_masks = burn_in_masks[:, step].unsqueeze(-1).type(inputs.dtype)\n",
        "            current_inps = inputs[:, step]\n",
        "            current_node_inds = node_inds[0][step]\n",
        "            current_graph_info = graph_info[0][step]\n",
        "            decoder_inp = current_burn_in_masks*current_inps + (1-current_burn_in_masks)*predictions\n",
        "            predictions, hidden = self.single_step_forward(decoder_inp, current_masks, current_graph_info, hidden)\n",
        "            preds.append(predictions)\n",
        "        return torch.stack(preds, dim=1)\n",
        "        \n",
        "    def copy_states(self, state):\n",
        "        if isinstance(state, tuple) or isinstance(state, list):\n",
        "            current_state = (state[0].clone(), state[1].clone())\n",
        "        else:\n",
        "            current_state = state.clone()\n",
        "        return current_state\n",
        "\n",
        "    def merge_hidden(self, hidden):\n",
        "        if isinstance(hidden[0], tuple) or isinstance(hidden[0], list):\n",
        "            result0 = torch.cat([x[0] for x in hidden], dim=0)\n",
        "            result1 = torch.cat([x[1] for x in hidden], dim=0)\n",
        "            return (result0, result1)\n",
        "        else:\n",
        "            return torch.cat(hidden, dim=0)\n",
        "\n",
        "    def predict_future_fixedwindow(self, inputs, burn_in_steps, prediction_steps, batch_size):\n",
        "        hidden = self.get_initial_hidden(inputs)\n",
        "        for step in range(burn_in_steps-1):\n",
        "            current_inputs = inputs[:, step]\n",
        "            predictions, hidden = self.single_step_forward(current_inputs, hidden)\n",
        "        all_timestep_preds = []\n",
        "        for window_ind in range(burn_in_steps - 1, inputs.size(1)-1, batch_size):\n",
        "            current_batch_preds = []\n",
        "            states = []\n",
        "            for step in range(batch_size):\n",
        "                if window_ind + step >= inputs.size(1):\n",
        "                    break\n",
        "                predictions = inputs[:, window_ind + step]\n",
        "                predictions, hidden = self.single_step_forward(predictions, hidden)\n",
        "                current_batch_preds.append(predictions)\n",
        "                tmp_decoder = self.copy_states(hidden)\n",
        "                states.append(tmp_decoder)\n",
        "            batch_hidden = self.merge_hidden(states)\n",
        "            current_batch_preds = torch.cat(current_batch_preds, 0)\n",
        "            current_timestep_preds = [current_batch_preds]\n",
        "            for step in range(prediction_steps - 1):\n",
        "                current_batch_preds, batch_hidden = self.single_step_forward(current_batch_preds, batch_hidden)\n",
        "                current_timestep_preds.append(current_batch_preds)\n",
        "            all_timestep_preds.append(torch.stack(current_timestep_preds, dim=1))\n",
        "        results = torch.cat(all_timestep_preds, dim=0)\n",
        "        return results.unsqueeze(0)\n",
        "\n",
        "    def nll(self, preds, target, masks):\n",
        "        if self.nll_loss_type == 'crossent':\n",
        "            return self.nll_crossent(preds, target, masks)\n",
        "        elif self.nll_loss_type == 'gaussian':\n",
        "            return self.nll_gaussian(preds, target, masks)\n",
        "        elif self.nll_loss_type == 'poisson':\n",
        "            return self.nll_poisson(preds, target, masks)\n",
        "\n",
        "    def nll_gaussian(self, preds, target, masks, add_const=False):\n",
        "        neg_log_p = ((preds - target) ** 2 / (2 * self.prior_variance))*masks.unsqueeze(-1)\n",
        "        const = 0.5 * np.log(2 * np.pi * self.prior_variance)\n",
        "        #neg_log_p += const\n",
        "        if self.normalize_nll_per_var:\n",
        "            raise NotImplementedError()\n",
        "        elif self.normalize_nll:\n",
        "            return (neg_log_p.sum(-1) + const*masks).view(preds.size(0), -1).sum(dim=-1)/(masks.view(masks.size(0), -1).sum(dim=1)+1e-8)\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def nll_crossent(self, preds, target, masks):\n",
        "        if self.normalize_nll:\n",
        "            loss = nn.BCEWithLogitsLoss(reduction='none')(preds, target)\n",
        "            return (loss*masks.unsqueeze(-1)).view(preds.size(0), -1).sum(dim=-1)/(masks.view(masks.size(0), -1).sum(dim=1))\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def nll_poisson(self, preds, target, masks):\n",
        "        if self.normalize_nll:\n",
        "            loss = nn.PoissonNLLLoss(reduction='none')(preds, target)\n",
        "            return (loss*masks.unsqueeze(-1)).view(preds.size(0), -1).sum(dim=-1)/(masks.view(masks.size(0), -1).sum(dim=1))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "class FullyConnectedBaseline_DynamicVars(RecurrentBaseline_DynamicVars):\n",
        "    def __init__(self, params):\n",
        "        super(FullyConnectedBaseline_DynamicVars, self).__init__(params)\n",
        "        n_hid = params['decoder_hidden']\n",
        "        out_size = params['input_size']\n",
        "        do_prob = params['decoder_dropout']\n",
        "        input_size = params['input_size']\n",
        "\n",
        "        self.msg_fc1 = nn.Linear(2*n_hid, n_hid)\n",
        "        self.msg_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.msg_out_shape = n_hid\n",
        "\n",
        "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
        "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
        "\n",
        "        self.input_r = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_i = nn.Linear(input_size, n_hid, bias=True)\n",
        "        self.input_n = nn.Linear(input_size, n_hid, bias=True)\n",
        "\n",
        "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
        "        self.out_fc3 = nn.Linear(n_hid, out_size)\n",
        "\n",
        "        print('Using learned recurrent interaction net decoder.')\n",
        "\n",
        "        self.dropout_prob = do_prob\n",
        "\n",
        "    def get_initial_hidden(self, inputs):\n",
        "        return torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "\n",
        "    def single_step_forward(self, inputs, node_masks, graph_info, hidden):\n",
        "        # Input Size: [batch, num_vars, input_size]\n",
        "        # Hidden Size: [batch, num_vars, rnn_hidden]\n",
        "        # Edges size: [batch, num_edges, num_edge_types]\n",
        "        if self.training:\n",
        "            dropout_prob = self.dropout_prob\n",
        "        else:\n",
        "            dropout_prob = 0.\n",
        "        \n",
        "        max_num_vars = inputs.size(1)\n",
        "        node_inds = node_masks.nonzero()[:, -1]\n",
        "        current_hidden = hidden[:, node_inds]\n",
        "        current_inputs = inputs[:, node_inds]\n",
        "        num_vars = current_hidden.size(1)\n",
        "        if num_vars > 1:\n",
        "            send_edges, recv_edges, edge2node_inds = graph_info\n",
        "            send_edges, recv_edges, edge2node_inds = send_edges.cuda(non_blocking=True), recv_edges.cuda(non_blocking=True), edge2node_inds.cuda(non_blocking=True)\n",
        "\n",
        "            receivers = current_hidden[:, recv_edges]\n",
        "            senders = current_hidden[:, send_edges]\n",
        "\n",
        "            # pre_msg: [batch, num_edges, 2*msg_out]\n",
        "            pre_msg = torch.cat([receivers, senders], dim=-1)\n",
        "\n",
        "            msg = torch.tanh(self.msg_fc1(pre_msg))\n",
        "            msg = F.dropout(msg, p=dropout_prob)\n",
        "            msg = torch.tanh(self.msg_fc2(msg))\n",
        "            all_msgs = msg\n",
        "\n",
        "            incoming = all_msgs[:, edge2node_inds[:, 0], :].clone()\n",
        "            for i in range(1, edge2node_inds.size(1)):\n",
        "                incoming += all_msgs[:, edge2node_inds[:, i], :]\n",
        "            agg_msgs = incoming/(num_vars-1)\n",
        "        elif num_vars == 0:\n",
        "            pred_all = torch.zeros(inputs.size(0), max_num_vars, inputs.size(-1), device=inputs.device)\n",
        "            return pred_all, hidden\n",
        "        else:\n",
        "            agg_msgs = torch.zeros(current_inputs.size(0), num_vars, self.msg_out_shape, device=inputs.device)\n",
        "\n",
        "\n",
        "        # GRU-style gated aggregation\n",
        "        inp_r = self.input_r(current_inputs).view(current_inputs.size(0), num_vars, -1)\n",
        "        inp_i = self.input_i(current_inputs).view(current_inputs.size(0), num_vars, -1)\n",
        "        inp_n = self.input_n(current_inputs).view(current_inputs.size(0), num_vars, -1)\n",
        "        r = torch.sigmoid(inp_r + self.hidden_r(agg_msgs))\n",
        "        i = torch.sigmoid(inp_i + self.hidden_i(agg_msgs))\n",
        "        n = torch.tanh(inp_n + r*self.hidden_h(agg_msgs))\n",
        "        current_hidden = (1 - i)*n + i*current_hidden\n",
        "\n",
        "        # Output MLP\n",
        "        pred = F.dropout(F.relu(self.out_fc1(current_hidden)), p=dropout_prob)\n",
        "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=dropout_prob)\n",
        "        pred = self.out_fc3(pred)\n",
        "\n",
        "        pred = current_inputs + pred\n",
        "        hidden = hidden.clone()\n",
        "        hidden[:, node_inds] = current_hidden\n",
        "        pred_all = torch.zeros(inputs.size(0), max_num_vars, inputs.size(-1), device=inputs.device)\n",
        "        pred_all[0, node_inds] = pred\n",
        "\n",
        "        return pred_all, hidden"
      ],
      "metadata": {
        "id": "9nT5oBdSZA4G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "\n",
        "def build_model(params):\n",
        "    if params['model_type'] == 'dnri':\n",
        "        dynamic_vars = params.get('dynamic_vars', False)\n",
        "        if dynamic_vars:\n",
        "            model = DNRI_DynamicVars(params)\n",
        "        else:\n",
        "            model = DNRI(params)\n",
        "        print(\"dNRI MODEL: \",model)\n",
        "    elif params['model_type'] == 'fc_baseline':\n",
        "        dynamic_vars = params.get('dynamic_vars', False)\n",
        "        if dynamic_vars:\n",
        "            model = FullyConnectedBaseline_DynamicVars(params)\n",
        "        else:\n",
        "            model = FullyConnectedBaseline(params)\n",
        "        print(\"FCBaseline: \",model)\n",
        "    else:\n",
        "        num_vars = params['num_vars']\n",
        "        graph_type = params['graph_type']\n",
        "\n",
        "        # Build Encoder\n",
        "        encoder = RefMLPEncoder(params)\n",
        "        print(\"ENCODER: \",encoder)\n",
        "\n",
        "        # Build Decoder\n",
        "        decoder = GraphRNNDecoder(params)\n",
        "        print(\"DECODER: \",decoder)\n",
        "        if graph_type == 'dynamic':\n",
        "            model = DynamicNRI(num_vars, encoder, decoder, params)\n",
        "        else:\n",
        "            model = StaticNRI(num_vars, encoder, decoder, params)\n",
        "\n",
        "    if params['load_best_model']:\n",
        "        print(\"LOADING BEST MODEL\")\n",
        "        path = os.path.join(params['working_dir'], 'best_model')\n",
        "        model.load(path)\n",
        "    elif params['load_model']:\n",
        "        print(\"LOADING MODEL FROM SPECIFIED PATH\")\n",
        "        model.load(params['load_model'])\n",
        "    if params['gpu']:\n",
        "        model.cuda()\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "rzUdzq4oWlju"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Code from NRI.\n",
        "def normalize(data, data_max, data_min):\n",
        "\treturn (data - data_min) * 2 / (data_max - data_min) - 1\n",
        "\n",
        "\n",
        "def unnormalize(data, data_max, data_min):\n",
        "\treturn (data + 1) * (data_max - data_min) / 2. + data_min\n",
        "\n",
        "\n",
        "def get_edge_inds(num_vars):\n",
        "\tedges = []\n",
        "\tfor i in range(num_vars):\n",
        "\t\tfor j in range(num_vars):\n",
        "\t\t\tif i == j:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tedges.append([i, j])\n",
        "\treturn edges"
      ],
      "metadata": {
        "id": "HwstDIX7Zvxb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import argparse, os\n",
        "\n",
        "\n",
        "class SmallSynthData(Dataset):\n",
        "    def __init__(self, data_path, mode, params):\n",
        "        self.mode = mode\n",
        "        self.data_path = data_path\n",
        "        if self.mode == 'train':\n",
        "            path = os.path.join(data_path, 'train_feats')\n",
        "            edge_path = os.path.join(data_path, 'train_edges')\n",
        "        elif self.mode == 'val':\n",
        "            path = os.path.join(data_path, 'val_feats')\n",
        "            edge_path = os.path.join(data_path, 'val_edges')\n",
        "        elif self.mode == 'test':\n",
        "            path = os.path.join(data_path, 'test_feats')\n",
        "            edge_path = os.path.join(data_path, 'test_edges')\n",
        "        self.feats = torch.load(path)\n",
        "        self.edges = torch.load(edge_path)\n",
        "        self.same_norm = params['same_data_norm']\n",
        "        self.no_norm = params['no_data_norm']\n",
        "        if not self.no_norm:\n",
        "            self._normalize_data()\n",
        "\n",
        "    def _normalize_data(self):\n",
        "        train_data = torch.load(os.path.join(self.data_path, 'train_feats'))\n",
        "        if self.same_norm:\n",
        "            self.feat_max = train_data.max()\n",
        "            self.feat_min = train_data.min()\n",
        "            self.feats = (self.feats - self.feat_min)*2/(self.feat_max-self.feat_min) - 1\n",
        "        else:\n",
        "            self.loc_max = train_data[:, :, :, :2].max()\n",
        "            self.loc_min = train_data[:, :, :, :2].min()\n",
        "            self.vel_max = train_data[:, :, :, 2:].max()\n",
        "            self.vel_min = train_data[:, :, :, 2:].min()\n",
        "            self.feats[:,:,:, :2] = (self.feats[:,:,:,:2]-self.loc_min)*2/(self.loc_max - self.loc_min) - 1\n",
        "            self.feats[:,:,:,2:] = (self.feats[:,:,:,2:]-self.vel_min)*2/(self.vel_max-self.vel_min)-1\n",
        "\n",
        "    def unnormalize(self, data):\n",
        "        if self.no_norm:\n",
        "            return data\n",
        "        elif self.same_norm:\n",
        "            return (data + 1) * (self.feat_max - self.feat_min) / 2. + self.feat_min\n",
        "        else:\n",
        "            result1 = (data[:, :, :, :2] + 1) * (self.loc_max - self.loc_min) / 2. + self.loc_min\n",
        "            result2 = (data[:, :, :, 2:] + 1) * (self.vel_max - self.vel_min) / 2. + self.vel_min\n",
        "            return np.concatenate([result1, result2], axis=-1)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'inputs': self.feats[idx], 'edges':self.edges[idx]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.feats)\n",
        "        \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--output_dir', required=True)\n",
        "    parser.add_argument('--num_train', type=int, default=100)\n",
        "    parser.add_argument('--num_val', type=int, default=100)\n",
        "    parser.add_argument('--num_test', type=int, default=100)\n",
        "    parser.add_argument('--num_time_steps', type=int, default=50)\n",
        "    parser.add_argument('--pull_factor', type=float, default=0.1)\n",
        "    parser.add_argument('--push_factor', type=float, default=0.05)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    np.random.seed(1)\n",
        "    all_data = []\n",
        "    all_edges = []\n",
        "    num_sims = args.num_train + args.num_val + args.num_test\n",
        "    flip_count = 0\n",
        "    total_steps = 0\n",
        "    for sim in range(num_sims):\n",
        "        p1_loc = np.random.uniform(-2, -1, size=(2))\n",
        "        p1_vel = np.random.uniform(0.05, 0.1, size=(2))\n",
        "        p2_loc = np.random.uniform(1, 2, size=(2))\n",
        "        p2_vel = np.random.uniform(-0.05, -0.1, size=(2))\n",
        "        p3_loc = np.random.uniform(-1, 1, size=(2))\n",
        "        p3_vel = np.random.uniform(-0.05, 0.05, size=(2))\n",
        "\n",
        "        current_feats = []\n",
        "        current_edges = []\n",
        "        for time_step in range(args.num_time_steps):\n",
        "            current_edge = np.array([0,0,0,0,0,0])\n",
        "            current_edges.append(current_edge)\n",
        "            if np.linalg.norm(p3_loc - p1_loc) < 1:\n",
        "                norm = np.linalg.norm(p3_loc - p1_loc)\n",
        "                coef = 1 - norm\n",
        "                dir_1 = (p3_loc - p1_loc)/norm\n",
        "                p3_vel += args.push_factor*coef*dir_1\n",
        "                current_edge[1] = 1\n",
        "            if np.linalg.norm(p3_loc - p2_loc) < 1:\n",
        "                norm = np.linalg.norm(p3_loc - p2_loc)\n",
        "                coef = 1 - norm\n",
        "                dir_2 = (p3_loc - p2_loc)/norm\n",
        "                p3_vel += args.push_factor*coef*dir_2\n",
        "                current_edge[3] = 1\n",
        "\n",
        "            p1_loc += p1_vel\n",
        "            p2_loc += p2_vel\n",
        "            p3_loc += p3_vel\n",
        "            p1_feat = np.concatenate([p1_loc, p1_vel])\n",
        "            p2_feat = np.concatenate([p2_loc, p2_vel])\n",
        "            p3_feat = np.concatenate([p3_loc, p3_vel])\n",
        "            new_feat = np.stack([p1_feat, p2_feat, p3_feat])\n",
        "            current_feats.append(new_feat)\n",
        "        all_data.append(np.stack(current_feats))\n",
        "        all_edges.append(np.stack(current_edges))\n",
        "        \n",
        "    all_data = np.stack(all_data)\n",
        "    train_data = torch.FloatTensor(all_data[:args.num_train])\n",
        "    val_data = torch.FloatTensor(all_data[args.num_train:args.num_train+args.num_val])\n",
        "    test_data = torch.FloatTensor(all_data[args.num_train+args.num_val:])\n",
        "    train_path = os.path.join(args.output_dir, 'train_feats')\n",
        "    torch.save(train_data, train_path)\n",
        "    val_path = os.path.join(args.output_dir, 'val_feats')\n",
        "    torch.save(val_data, val_path)\n",
        "    test_path = os.path.join(args.output_dir, 'test_feats')\n",
        "    torch.save(test_data, test_path)\n",
        "\n",
        "    train_edges = torch.FloatTensor(all_edges[:args.num_train])\n",
        "    val_edges = torch.FloatTensor(all_edges[args.num_train:args.num_train+args.num_val])\n",
        "    test_edges = torch.FloatTensor(all_edges[args.num_train+args.num_val:])\n",
        "    train_path = os.path.join(args.output_dir, 'train_edges')\n",
        "    torch.save(train_edges, train_path)\n",
        "    val_path = os.path.join(args.output_dir, 'val_edges')\n",
        "    torch.save(val_edges, val_path)\n",
        "    test_path = os.path.join(args.output_dir, 'test_edges')\n",
        "    torch.save(test_edges, test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "aVoE0RFaZk85",
        "outputId": "28e05ab9-c19c-4b1e-8521-137138976fa7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] --output_dir OUTPUT_DIR\n",
            "                             [--num_train NUM_TRAIN] [--num_val NUM_VAL]\n",
            "                             [--num_test NUM_TEST]\n",
            "                             [--num_time_steps NUM_TIME_STEPS]\n",
            "                             [--pull_factor PULL_FACTOR]\n",
            "                             [--push_factor PUSH_FACTOR]\n",
            "ipykernel_launcher.py: error: the following arguments are required: --output_dir\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np \n",
        "import random\n",
        "\n",
        "\n",
        "def seed(seed_val):\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    random.seed(seed_val)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "ehGjo_ebaOmW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "def build_scheduler(opt, params):\n",
        "    lr_decay_factor = params.get('lr_decay_factor')\n",
        "    lr_decay_steps = params.get('lr_decay_steps')\n",
        "    if lr_decay_factor:\n",
        "        return torch.optim.lr_scheduler.StepLR(opt, lr_decay_steps, lr_decay_factor)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "class build_writers:\n",
        "    def __init__(self, working_dir, is_test=False):\n",
        "        self.writer_dir = os.path.join(working_dir, 'logs/')\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __enter__(self):\n",
        "        train_writer_dir = os.path.join(self.writer_dir, 'train')\n",
        "        val_writer_dir = os.path.join(self.writer_dir, 'val')\n",
        "        self.train_writer = SummaryWriter(train_writer_dir)\n",
        "        self.val_writer = SummaryWriter(val_writer_dir)\n",
        "        if self.is_test:\n",
        "            test_writer_dir = os.path.join(self.writer_dir, 'test')\n",
        "            self.test_writer = SummaryWriter(test_writer_dir)\n",
        "            return self.train_writer, self.val_writer, self.test_writer\n",
        "        else:\n",
        "            return self.train_writer, self.val_writer\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        self.train_writer.close()\n",
        "        self.val_writer.close()\n",
        "        if self.is_test:\n",
        "            self.test_writer.close()"
      ],
      "metadata": {
        "id": "2HxlfPhWaZDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "\n",
        "import time, os\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def train(model, train_data, val_data, params, train_writer, val_writer):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    val_batch_size = params.get('val_batch_size', batch_size)\n",
        "    if val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "    accumulate_steps = params.get('accumulate_steps')\n",
        "    training_scheduler = params.get('training_scheduler', None)\n",
        "    num_epochs = params.get('num_epochs', 100)\n",
        "    val_interval = params.get('val_interval', 1)\n",
        "    val_start = params.get('val_start', 0)\n",
        "    clip_grad = params.get('clip_grad', None)\n",
        "    clip_grad_norm = params.get('clip_grad_norm', None)\n",
        "    normalize_nll = params.get('normalize_nll', False)\n",
        "    normalize_kl = params.get('normalize_kl', False)\n",
        "    tune_on_nll = params.get('tune_on_nll', False)\n",
        "    verbose = params.get('verbose', False)\n",
        "    val_teacher_forcing = params.get('val_teacher_forcing', False)\n",
        "    continue_training = params.get('continue_training', False)\n",
        "    train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_data_loader = DataLoader(val_data, batch_size=val_batch_size)\n",
        "    lr = params['lr']\n",
        "    wd = params.get('wd', 0.)\n",
        "    mom = params.get('mom', 0.)\n",
        "    \n",
        "    model_params = [param for param in model.parameters() if param.requires_grad]\n",
        "    if params.get('use_adam', False):\n",
        "        opt = torch.optim.Adam(model_params, lr=lr, weight_decay=wd)\n",
        "    else:\n",
        "        opt = torch.optim.SGD(model_params, lr=lr, weight_decay=wd, momentum=mom)\n",
        "\n",
        "    working_dir = params['working_dir']\n",
        "    best_path = os.path.join(working_dir, 'best_model')\n",
        "    checkpoint_dir = os.path.join(working_dir, 'model_checkpoint')\n",
        "    training_path = os.path.join(working_dir, 'training_checkpoint')\n",
        "    if continue_training:\n",
        "        print(\"RESUMING TRAINING\")\n",
        "        model.load(checkpoint_dir)\n",
        "        train_params = torch.load(training_path)\n",
        "        start_epoch = train_params['epoch']\n",
        "        opt.load_state_dict(train_params['optimizer'])\n",
        "        best_val_result = train_params['best_val_result']\n",
        "        best_val_epoch = train_params['best_val_epoch']\n",
        "        print(\"STARTING EPOCH: \",start_epoch)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_epoch = -1\n",
        "        best_val_result = 10000000\n",
        "    \n",
        "    training_scheduler = train_utils.build_scheduler(opt, params)\n",
        "    end = start = 0 \n",
        "    misc.seed(1)\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        print(\"EPOCH\", epoch, (end-start))\n",
        "        model.train()\n",
        "        model.train_percent = epoch / num_epochs\n",
        "        start = time.time() \n",
        "        for batch_ind, batch in enumerate(train_data_loader):\n",
        "            inputs = batch['inputs']\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=True, return_logits=True)\n",
        "            loss.backward()\n",
        "            if verbose:\n",
        "                print(\"\\tBATCH %d OF %d: %f, %f, %f\"%(batch_ind+1, len(train_data_loader), loss.item(), loss_nll.mean().item(), loss_kl.mean().item()))\n",
        "            if accumulate_steps == -1 or (batch_ind+1)%accumulate_steps == 0:\n",
        "                if verbose and accumulate_steps > 0:\n",
        "                    print(\"\\tUPDATING WEIGHTS\")\n",
        "                if clip_grad is not None:\n",
        "                    nn.utils.clip_grad_value_(model.parameters(), clip_grad)\n",
        "                elif clip_grad_norm is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)        \n",
        "                opt.step()\n",
        "                opt.zero_grad()\n",
        "                if accumulate_steps > 0 and accumulate_steps > len(train_data_loader) - batch_ind - 1:\n",
        "                    break\n",
        "            \n",
        "        if training_scheduler is not None:\n",
        "            training_scheduler.step()\n",
        "        \n",
        "        if train_writer is not None:\n",
        "            train_writer.add_scalar('loss', loss.item(), global_step=epoch)\n",
        "            if normalize_nll:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item(), global_step=epoch)\n",
        "            else:\n",
        "                train_writer.add_scalar('NLL', loss_nll.mean().item()/(inputs.size(1)*inputs.size(2)), global_step=epoch)\n",
        "            \n",
        "            train_writer.add_scalar(\"KL Divergence\", loss_kl.mean().item(), global_step=epoch)\n",
        "        model.eval()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        total_nll = 0\n",
        "        total_kl = 0\n",
        "        if verbose:\n",
        "            print(\"COMPUTING VAL LOSSES\")\n",
        "        with torch.no_grad():\n",
        "            for batch_ind, batch in enumerate(val_data_loader):\n",
        "                inputs = batch['inputs']\n",
        "                if gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                loss, loss_nll, loss_kl, logits, _ = model.calculate_loss(inputs, is_train=False, teacher_forcing=val_teacher_forcing, return_logits=True)\n",
        "                total_kl += loss_kl.sum().item()\n",
        "                total_nll += loss_nll.sum().item()\n",
        "                if verbose:\n",
        "                    print(\"\\tVAL BATCH %d of %d: %f, %f\"%(batch_ind+1, len(val_data_loader), loss_nll.mean(), loss_kl.mean()))\n",
        "            \n",
        "        total_kl /= len(val_data)\n",
        "        total_nll /= len(val_data)\n",
        "        total_loss = model.kl_coef*total_kl + total_nll #TODO: this is a thing you fixed\n",
        "        if val_writer is not None:\n",
        "            val_writer.add_scalar('loss', total_loss, global_step=epoch)\n",
        "            val_writer.add_scalar(\"NLL\", total_nll, global_step=epoch)\n",
        "            val_writer.add_scalar(\"KL Divergence\", total_kl, global_step=epoch)\n",
        "        if tune_on_nll:\n",
        "            tuning_loss = total_nll\n",
        "        else:\n",
        "            tuning_loss = total_loss\n",
        "        if tuning_loss < best_val_result:\n",
        "            best_val_epoch = epoch\n",
        "            best_val_result = tuning_loss\n",
        "            print(\"BEST VAL RESULT. SAVING MODEL...\")\n",
        "            model.save(best_path)\n",
        "        model.save(checkpoint_dir)\n",
        "        torch.save({\n",
        "                    'epoch':epoch+1,\n",
        "                    'optimizer':opt.state_dict(),\n",
        "                    'best_val_result':best_val_result,\n",
        "                    'best_val_epoch':best_val_epoch,\n",
        "                   }, training_path)\n",
        "        print(\"EPOCH %d EVAL: \"%epoch)\n",
        "        print(\"\\tCURRENT VAL LOSS: %f\"%tuning_loss)\n",
        "        print(\"\\tBEST VAL LOSS:    %f\"%best_val_result)\n",
        "        print(\"\\tBEST VAL EPOCH:   %d\"%best_val_epoch)\n",
        "        end = time.time()\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "4vdJXF9FaLto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def eval_forward_prediction(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            batch_count += 1\n",
        "            if return_total_errors:\n",
        "                all_errors.append(F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1))\n",
        "            else:\n",
        "                total_se += F.mse_loss(model_preds, gt_predictions, reduction='none').view(model_preds.size(0), model_preds.size(1), -1).mean(dim=-1).sum(dim=0)\n",
        "    if return_total_errors:\n",
        "        return torch.cat(all_errors, dim=0)\n",
        "    else:\n",
        "        return total_se / len(dataset)\n",
        "\n",
        "def eval_forward_prediction_fixedwindow(model, dataset, burn_in_steps, forward_pred_steps, params, return_total_errors=False):\n",
        "    dataset.return_edges = False\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    data_loader = DataLoader(dataset, batch_size=1)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    total_count = torch.zeros(forward_pred_steps)\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        print(\"BATCH IND %d OF %d\"%(batch_ind+1, len(data_loader)))\n",
        "        with torch.no_grad():\n",
        "\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future_fixedwindow(inputs, burn_in_steps, forward_pred_steps, batch_size).cpu()\n",
        "            for window_ind in range(model_preds.size(1)):\n",
        "                current_preds = model_preds[:, window_ind]\n",
        "                start_ind = burn_in_steps + window_ind\n",
        "                gt_preds = inputs[:, start_ind:start_ind + forward_pred_steps].cpu()\n",
        "                if gt_preds.size(1) < forward_pred_steps:\n",
        "                    mask = torch.cat([torch.ones(gt_preds.size(1)), torch.zeros(forward_pred_steps - gt_preds.size(1))])\n",
        "                    gt_preds = torch.cat([gt_preds, torch.zeros(gt_preds.size(0), forward_pred_steps-gt_preds.size(1), gt_preds.size(2), gt_preds.size(3))], dim=1)\n",
        "                else:\n",
        "                    mask = torch.ones(forward_pred_steps)\n",
        "                total_se += F.mse_loss(current_preds, gt_preds, reduction='none').view(current_preds.size(0), current_preds.size(1), -1).mean(dim=-1).sum(dim=0).cpu()*mask\n",
        "                total_count += mask\n",
        "\n",
        "    return total_se / total_count\n",
        "\n",
        "\n",
        "def eval_forward_prediction_dynamicvars(model, dataset, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    collate_fn = params.get('collate_fn', None)\n",
        "    data_loader = DataLoader(dataset, batch_size=1, pin_memory=gpu, collate_fn=collate_fn)\n",
        "    model.eval()\n",
        "    total_se = 0\n",
        "    batch_count = 0\n",
        "    final_errors = torch.zeros(0)\n",
        "    final_counts = torch.zeros(0)\n",
        "    bad_count = 0\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        print(\"DATA POINT \",batch_ind)\n",
        "        inputs = batch['inputs']\n",
        "        gt_preds = inputs[0, 1:]\n",
        "        masks = batch['masks']\n",
        "        node_inds = batch.get('node_inds', None)\n",
        "        graph_info = batch.get('graph_info', None)\n",
        "        burn_in_masks = batch['burn_in_masks']\n",
        "        pred_masks = (masks.float() - burn_in_masks)[0, 1:]\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                masks = masks.cuda(non_blocking=True)\n",
        "                burn_in_masks = burn_in_masks.cuda(non_blocking=True)\n",
        "            model_preds = model.predict_future(inputs, masks, node_inds, graph_info, burn_in_masks)[0].cpu()\n",
        "            max_len = pred_masks.sum(dim=0).max().int().item()\n",
        "            if max_len > len(final_errors):\n",
        "                final_errors = torch.cat([final_errors, torch.zeros(max_len - len(final_errors))])\n",
        "                final_counts = torch.cat([final_counts, torch.zeros(max_len - len(final_counts))])\n",
        "            for var in range(masks.size(-1)):\n",
        "                var_gt = gt_preds[:, var]\n",
        "                var_preds = model_preds[:, var]\n",
        "                var_pred_masks = pred_masks[:, var]\n",
        "                var_losses = F.mse_loss(var_preds, var_gt, reduction='none').mean(dim=-1)*var_pred_masks\n",
        "                tmp_inds = torch.nonzero(var_pred_masks)\n",
        "                if len(tmp_inds) == 0:\n",
        "                    continue\n",
        "                for i in range(len(tmp_inds)-1):\n",
        "                    if tmp_inds[i+1] - tmp_inds[i] != 1:\n",
        "                        bad_count += 1\n",
        "                        break\n",
        "                num_entries = var_pred_masks.sum().int().item()\n",
        "                final_errors[:num_entries] += var_losses[tmp_inds[0].item():tmp_inds[0].item()+num_entries]\n",
        "                final_counts[:num_entries] += var_pred_masks[tmp_inds[0]:tmp_inds[0]+num_entries]\n",
        "    print(\"FINAL BAD COUNT: \",bad_count)\n",
        "    return final_errors/final_counts, final_counts"
      ],
      "metadata": {
        "id": "RNpuii-haje_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmGdYg-HTaIs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "\n",
        "def eval_edges(model, dataset, params):\n",
        "\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1000)\n",
        "    eval_metric = params.get('eval_metric')\n",
        "    num_edge_types = params['num_edge_types']\n",
        "    skip_first = params['skip_first']\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, pin_memory=gpu)\n",
        "    full_edge_count = 0.\n",
        "    model.eval()\n",
        "    correct_edges = 0.\n",
        "    edge_count = 0.\n",
        "    correct_0_edges = 0.\n",
        "    edge_0_count = 0.\n",
        "    correct_1_edges = 0.\n",
        "    edge_1_count = 0.\n",
        "\n",
        "    correct = num_predicted = num_gt = 0\n",
        "    all_edges = []\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch['edges'].long()\n",
        "        with torch.no_grad():\n",
        "            if gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "                gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "\n",
        "            _, _, _, edges, _ = model.calculate_loss(inputs, is_train=False, return_logits=True)\n",
        "            edges = edges.argmax(dim=-1)\n",
        "            all_edges.append(edges.cpu())\n",
        "            if len(edges.shape) == 3 and len(gt_edges.shape) == 2:\n",
        "                gt_edges = gt_edges.unsqueeze(1).expand(gt_edges.size(0), edges.size(1), gt_edges.size(1))\n",
        "            elif len(gt_edges.shape) == 3 and len(edges.shape) == 2:\n",
        "                edges = edges.unsqueeze(1).expand(edges.size(0), gt_edges.size(1), edges.size(1))\n",
        "            if edges.size(1) == gt_edges.size(1) - 1:\n",
        "                gt_edges = gt_edges[:, :-1]\n",
        "            edge_count += edges.numel()\n",
        "            full_edge_count += gt_edges.numel()\n",
        "            correct_edges += ((edges == gt_edges)).sum().item()\n",
        "            edge_0_count += (gt_edges == 0).sum().item()\n",
        "            edge_1_count += (gt_edges == 1).sum().item()\n",
        "            correct_0_edges += ((edges == gt_edges)*(gt_edges == 0)).sum().item()\n",
        "            correct_1_edges += ((edges == gt_edges)*(gt_edges == 1)).sum().item()\n",
        "            correct += (edges*gt_edges).sum().item()\n",
        "            num_predicted += edges.sum().item()\n",
        "            num_gt += gt_edges.sum().item()\n",
        "    prec = correct / (num_predicted + 1e-8)\n",
        "    rec = correct / (num_gt + 1e-8)\n",
        "    f1 = 2*prec*rec / (prec+rec+1e-6)\n",
        "    all_edges = torch.cat(all_edges)\n",
        "    return f1, correct_edges / (full_edge_count + 1e-8), correct_0_edges / (edge_0_count + 1e-8), correct_1_edges / (edge_1_count + 1e-8), all_edges\n",
        "\n",
        "def plot_sample(model, dataset, num_samples, params):\n",
        "    gpu = params.get('gpu', False)\n",
        "    batch_size = params.get('batch_size', 1)\n",
        "    use_gt_edges = params.get('use_gt_edges')\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
        "    model.eval()\n",
        "    batch_count = 0\n",
        "    all_errors = []\n",
        "    burn_in_steps = 10\n",
        "    forward_pred_steps = 40\n",
        "    for batch_ind, batch in enumerate(data_loader):\n",
        "        inputs = batch['inputs']\n",
        "        gt_edges = batch.get('edges', None)\n",
        "        with torch.no_grad():\n",
        "            model_inputs = inputs[:, :burn_in_steps]\n",
        "            gt_predictions = inputs[:, burn_in_steps:burn_in_steps+forward_pred_steps]\n",
        "            if gpu:\n",
        "                model_inputs = model_inputs.cuda(non_blocking=True)\n",
        "                if gt_edges is not None and use_gt_edges:\n",
        "                    gt_edges = gt_edges.cuda(non_blocking=True)\n",
        "            if not use_gt_edges:\n",
        "                gt_edges=None\n",
        "            model_preds = model.predict_future(model_inputs, forward_pred_steps).cpu()\n",
        "            #total_se += F.mse_loss(model_preds, gt_predictions).item()\n",
        "            print(\"MSE: \", torch.nn.functional.mse_loss(model_preds, gt_predictions).item())\n",
        "            batch_count += 1\n",
        "        fig, ax = plt.subplots()\n",
        "        unnormalized_preds = dataset.unnormalize(model_preds)\n",
        "        unnormalized_gt = dataset.unnormalize(inputs)\n",
        "        def update(frame):\n",
        "            ax.clear()\n",
        "            ax.plot(unnormalized_gt[0, frame, 0, 0], unnormalized_gt[0, frame, 0, 1], 'bo')\n",
        "            ax.plot(unnormalized_gt[0, frame, 1, 0], unnormalized_gt[0, frame, 1, 1], 'ro')\n",
        "            ax.plot(unnormalized_gt[0, frame, 2, 0], unnormalized_gt[0, frame, 2, 1], 'go')\n",
        "            if frame >= burn_in_steps:\n",
        "                tmp_fr = frame - burn_in_steps\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 0, 0], unnormalized_preds[0, tmp_fr, 0, 1], 'bo', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 1, 0], unnormalized_preds[0, tmp_fr, 1, 1], 'ro', alpha=0.5)\n",
        "                ax.plot(unnormalized_preds[0, tmp_fr, 2, 0], unnormalized_preds[0, tmp_fr, 2, 1], 'go', alpha=0.5)\n",
        "            ax.set_xlim(-6, 6)\n",
        "            ax.set_ylim(-6, 6)\n",
        "        ani = animation.FuncAnimation(fig, update, interval=100, frames=burn_in_steps+forward_pred_steps)\n",
        "        path = os.path.join(params['working_dir'], 'pred_trajectory_%d.mp4'%batch_ind)\n",
        "        ani.save(path, codec='mpeg4')\n",
        "        if batch_count >= num_samples:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = build_flags()\n",
        "    parser.add_argument('--data_path')\n",
        "    parser.add_argument('--same_data_norm', action='store_true')\n",
        "    parser.add_argument('--no_data_norm', action='store_true')\n",
        "    parser.add_argument('--error_out_name', default='prediction_errors_%dstep.npy')\n",
        "    parser.add_argument('--prior_variance', type=float, default=5e-5)\n",
        "    parser.add_argument('--test_burn_in_steps', type=int, default=10)\n",
        "    parser.add_argument('--error_suffix')\n",
        "    parser.add_argument('--subject_ind', type=int, default=-1)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    params = vars(args)\n",
        "    seed(args.seed)\n",
        "\n",
        "    params['num_vars'] = 3\n",
        "    params['input_size'] = 4\n",
        "    params['input_time_steps'] = 50\n",
        "    params['nll_loss_type'] = 'gaussian'\n",
        "    train_data = SmallSynthData(args.data_path, 'train', params)\n",
        "    val_data = SmallSynthData(args.data_path, 'val', params)\n",
        "\n",
        "    model = build_model(params)\n",
        "    if args.mode == 'train':\n",
        "        with build_writers(args.working_dir) as (train_writer, val_writer):\n",
        "            train.train(model, train_data, val_data, params, train_writer, val_writer)\n",
        " \n",
        "    elif args.mode == 'eval':\n",
        "        test_data = SmallSynthData(args.data_path, 'test', params)\n",
        "        forward_pred = 50 - args.test_burn_in_steps\n",
        "        test_mse  = eval_forward_prediction(model, test_data, args.test_burn_in_steps, forward_pred, params)\n",
        "        path = os.path.join(args.working_dir, args.error_out_name%args.test_burn_in_steps)\n",
        "        np.save(path, test_mse.cpu().numpy())\n",
        "        test_mse_1 = test_mse[0].item()\n",
        "        test_mse_15 = test_mse[14].item()\n",
        "        test_mse_25 = test_mse[24].item()\n",
        "        print(\"FORWARD PRED RESULTS:\")\n",
        "        print(\"\\t1 STEP: \",test_mse_1)\n",
        "        print(\"\\t15 STEP: \",test_mse_15)\n",
        "        print(\"\\t25 STEP: \",test_mse_25)\n",
        "\n",
        "\n",
        "        f1, all_acc, acc_0, acc_1, edges = eval_edges(model, val_data, params)\n",
        "        print(\"Val Edge results:\")\n",
        "        print(\"\\tF1: \",f1)\n",
        "        print(\"\\tAll predicted edge accuracy: \",all_acc)\n",
        "        print(\"\\tFirst Edge Acc: \",acc_0)\n",
        "        print(\"\\tSecond Edge Acc: \",acc_1)\n",
        "        out_dir = os.path.join(args.working_dir, 'preds')\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        out_path = os.path.join(out_dir, 'encoder_edges.npy')\n",
        "        np.save(out_path, edges.numpy())\n",
        "\n",
        "        plot_sample(model, test_data, args.test_burn_in_steps, params)\n",
        "    elif args.mode == 'record_predictions':\n",
        "        model.eval()\n",
        "        burn_in = args.test_burn_in_steps\n",
        "        forward_pred = 50 - args.test_burn_in_steps\n",
        "        test_data = SmallSynthData(args.data_path, 'test', params)\n",
        "        if args.subject_ind == -1:\n",
        "            val_data_loader = DataLoader(test_data, batch_size=params['batch_size'])\n",
        "            all_predictions = []\n",
        "            all_edges = []\n",
        "            for batch_ind,batch in enumerate(val_data_loader):\n",
        "                print(\"BATCH %d of %d\"%(batch_ind+1, len(val_data_loader)))\n",
        "                inputs = batch['inputs']\n",
        "                if args.gpu:\n",
        "                    inputs = inputs.cuda(non_blocking=True)\n",
        "                with torch.no_grad():\n",
        "                    predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "                    all_predictions.append(predictions)\n",
        "                    all_edges.append(edges)\n",
        "            if args.error_suffix is not None:\n",
        "                out_path = os.path.join(args.working_dir, 'preds/', 'all_test_subjects_%s.npy'%args.error_suffix)\n",
        "            else:\n",
        "                out_path = os.path.join(args.working_dir, 'preds/', 'all_test_subjects.npy')\n",
        "\n",
        "            predictions = torch.cat(all_predictions, dim=0)\n",
        "            edges = torch.cat(all_edges, dim=0)\n",
        "\n",
        "        else:\n",
        "            data = test_data[args.subject_ind]\n",
        "            inputs = data['inputs'].unsqueeze(0)\n",
        "            if args.gpu:\n",
        "                inputs = inputs.cuda(non_blocking=True)\n",
        "            with torch.no_grad():\n",
        "                predictions, edges = model.predict_future(inputs[:, :burn_in], forward_pred, return_edges=True, return_everything=True)\n",
        "                predictions = predictions.squeeze(0)\n",
        "                edges = edges.squeeze(0)\n",
        "            out_path = os.path.join(args.working_dir, 'preds/', 'subject_%d.npy'%args.subject_ind)\n",
        "        tmp_dir = os.path.join(args.working_dir, 'preds/')\n",
        "        if not os.path.exists(tmp_dir):\n",
        "            os.makedirs(tmp_dir)\n",
        "        torch.save([predictions.cpu(), edges.cpu()], out_path)"
      ]
    }
  ]
}